{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce28585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from neurovlm.data import get_data_dir\n",
    "\n",
    "# NeuroConText imports, clone the neurocontext repo and fetch their data\n",
    "neurocontext_dir = '/Users/anons/projects/NeuroConText'\n",
    "data_dir = Path('/Users/anon/projects/NeuroConText/data_NeuroConText')\n",
    "sys.path.append(neurocontext_dir)\n",
    "from layers import ClipModel, ProjectionHead, ResidualHead\n",
    "from losses import ClipLoss\n",
    "from training import predict, train\n",
    "from metrics import mix_match\n",
    "from src.utils import recall_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ade63d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NeuroConText pmids\n",
    "train_pmids = np.array(list(pd.read_pickle(data_dir/ \"train_pmids.pkl\")))\n",
    "test_pmids = np.array(list(pd.read_pickle(data_dir / \"test_pmids.pkl\")))\n",
    "pmids = np.concatenate((train_pmids, test_pmids))\n",
    "pmids = np.sort(pmids)\n",
    "\n",
    "# Load neurovlm data\n",
    "neurolm_dir = get_data_dir()\n",
    "df = pd.read_parquet(get_data_dir() / \"publications_more.parquet\")\n",
    "assert pd.Series(pmids).isin(df[\"pmid\"]).all() # we have all the ids the neurocontext has and 10k more\n",
    "\n",
    "# Filter by neurocontext pmids\n",
    "df_nc = df[df[\"pmid\"].isin(pmids)].copy()\n",
    "df_nc.sort_values(by=\"pmid\", inplace=True)\n",
    "df_nc[\"description\"] = df_nc[\"description\"].str.strip(\" \").str.strip(\"\\n\")\n",
    "df_nc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# NeuroConText embeddings\n",
    "output_dir = Path(data_dir)\n",
    "\n",
    "model_dir = get_data_dir() / \"models\"\n",
    "model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "test_gaussian_embeddings = pd.read_pickle(data_dir / 'test_gaussian_embeddings.pkl')\n",
    "train_gaussian_embeddings = pd.read_pickle(data_dir / 'train_gaussian_embeddings.pkl')\n",
    "test_text_embeddings = pd.read_pickle(data_dir / 'test_abstract_embeddings.pkl').values\n",
    "train_text_embeddings = pd.read_pickle(data_dir / 'train_abstract_embeddings.pkl').values\n",
    "\n",
    "sorted_indices = np.argsort(pmids)\n",
    "assert (pmids[sorted_indices] == df_nc[\"pmid\"]).all()\n",
    "\n",
    "dataset = TensorDataset(\n",
    "    torch.from_numpy(\n",
    "        np.vstack((train_gaussian_embeddings, test_gaussian_embeddings))[sorted_indices]\n",
    "    ).float(),\n",
    "    torch.from_numpy(\n",
    "        np.vstack((train_text_embeddings, test_text_embeddings))[sorted_indices]\n",
    "    ).float(),\n",
    ")\n",
    "\n",
    "# NeuroConText settings\n",
    "plot_verbose = True\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0.1\n",
    "dropout = 0.6\n",
    "output_size = test_gaussian_embeddings.shape[1]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "criterion = ClipLoss()\n",
    "is_clip_loss = criterion.__class__ == ClipLoss\n",
    "loss_specific_kwargs = {\n",
    "    \"logit_scale\": 10 if is_clip_loss else np.log(10),\n",
    "    \"logit_bias\": None if is_clip_loss else -10,\n",
    "}\n",
    "val_size = 1000\n",
    "\n",
    "# NeuroVLM embeddings\n",
    "latent_text_specter, pmids_neurovlm = torch.load(neurolm_dir / \"latent_specter2_adhoc.pt\", weights_only=False).values()\n",
    "latent_neuro = torch.load(neurolm_dir / \"latent_neuro.pt\")\n",
    "autoencoder = torch.load(neurolm_dir / \"autoencoder.pt\", weights_only=False)\n",
    "decoder = autoencoder.decoder.to(\"cpu\")\n",
    "mask = pd.Series(pmids_neurovlm).isin(pmids) # mask to match neurocontext corpus\n",
    "pmids_neurovlm = pmids_neurovlm[mask]\n",
    "latent_neuro = latent_neuro[mask]\n",
    "latent_text_specter = latent_text_specter[mask]\n",
    "assert (pmids_neurovlm == pmids).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810eec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2200, Recall@20: 0.5938, Recall@200: 0.5938\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2103, Recall@20: 0.5832, Recall@200: 0.5832\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:01<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2166, Recall@20: 0.5880, Recall@200: 0.5880\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:07<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2302, Recall@20: 0.5928, Recall@200: 0.5928\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:05<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2269, Recall@20: 0.5893, Recall@200: 0.5893\n",
      "Fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:05<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2100, Recall@20: 0.5806, Recall@200: 0.5806\n",
      "Fold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:06<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2245, Recall@20: 0.5830, Recall@200: 0.5830\n",
      "Fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:06<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2187, Recall@20: 0.5602, Recall@200: 0.5602\n",
      "Fold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2163, Recall@20: 0.6004, Recall@200: 0.6004\n",
      "Fold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:58<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1984, Recall@20: 0.5573, Recall@200: 0.5573\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "recall_fn = partial(recall_n, thresh=0.95, reduce_mean=True)\n",
    "recall_20_nc, recall_200_nc = np.zeros(10), np.zeros(10)\n",
    "recall_20_nv, recall_200_nv = np.zeros(10), np.zeros(10)\n",
    "mix_match_nc = np.zeros(10)\n",
    "\n",
    "# CV\n",
    "n_epochs_nc = 50\n",
    "kfolds = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "\n",
    "for i, (inds_train, inds_test) in enumerate(kfolds.split(dataset)):\n",
    "\n",
    "    print(f\"Fold: {i}\")\n",
    "\n",
    "    # Data loaders and output directory\n",
    "    fold_dir = get_data_dir() / \"models\" / \"tmp\"\n",
    "    fold_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.random.seed(i)\n",
    "    np.random.shuffle(inds_train)\n",
    "\n",
    "    inds_val = inds_train[:val_size] # split train into (train, val)\n",
    "    inds_train = inds_train[val_size:]\n",
    "\n",
    "    train_dataset = TensorDataset(*dataset[inds_train])\n",
    "    test_dataset = TensorDataset(*dataset[inds_test])\n",
    "    val_dataset = TensorDataset(*dataset[inds_val])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # NeuroConText\n",
    "    model = ClipModel(\n",
    "        image_model=nn.Sequential(\n",
    "            ResidualHead(output_size, dropout=dropout),\n",
    "            ResidualHead(output_size, dropout=dropout),\n",
    "            ResidualHead(output_size, dropout=dropout),\n",
    "        ),\n",
    "        text_model=nn.Sequential(\n",
    "            ProjectionHead(train_text_embeddings.shape[1], output_size, dropout=dropout),\n",
    "            ResidualHead(output_size, dropout=dropout),\n",
    "            ResidualHead(output_size, dropout=dropout),\n",
    "        ),\n",
    "        **loss_specific_kwargs,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    clip_model, clip_train_loss, clip_val_loss, callback_outputs = train(\n",
    "        model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=None,\n",
    "        criterion=criterion,\n",
    "        num_epochs=n_epochs_nc,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "        output_dir=fold_dir,\n",
    "        callbacks=[],\n",
    "    )\n",
    "\n",
    "\n",
    "    # Metrics\n",
    "    with torch.no_grad():\n",
    "        clip_model.load_state_dict(torch.load(fold_dir / \"best_val.pt\"))\n",
    "        image_embeddings_nc, text_embeddings_nc = predict(clip_model, test_loader, device=device)\n",
    "        image_embeddings_nc /= image_embeddings_nc.norm(dim=1)[:, None]\n",
    "        text_embeddings_nc /= text_embeddings_nc.norm(dim=1)[:, None]\n",
    "\n",
    "    # Neuorcontext\n",
    "    similarity = (image_embeddings_nc @ text_embeddings_nc.T).softmax(dim=1).numpy()\n",
    "    recall_20_nc[i] = recall_fn(similarity, np.eye(len(similarity)), n_first=20)\n",
    "    recall_200_nc[i] = recall_fn(similarity, np.eye(len(similarity)), n_first=200)\n",
    "    mix_match_nc[i] = mix_match(similarity)\n",
    "    print(f\"Test Loss: {recall_20_nc[i]:.4f}, Recall@20: {recall_200_nc[i]:.4f}, Recall@200: {recall_200_nc[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773e50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(neurolm_dir / \"recall_20_nc.npy\", recall_20_nc)\n",
    "np.save(neurolm_dir / \"recall_200_nc.npy\", recall_200_nc)\n",
    "np.save(neurolm_dir / \"mix_match_nc.npy\", mix_match_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28349d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a9dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
