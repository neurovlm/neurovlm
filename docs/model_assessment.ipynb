{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Assessment",
   "id": "f8d6a38a66c30c9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:09:26.522597Z",
     "start_time": "2025-11-18T21:09:26.517657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle, gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import maskers\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn.image import resample_img\n",
    "\n",
    "from neurovlm.data import get_data_dir\n",
    "from neurovlm.models import Specter\n",
    "\n",
    "from neurovlm.brain_input import search_papers_from_brain, search_wiki_from_brain"
   ],
   "id": "a001b2f7b2f8bc71",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:09:31.052570Z",
     "start_time": "2025-11-18T21:09:26.622661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "get_data_dir()\n",
    "\n",
    "with gzip.open(get_data_dir() / f\"networks_arrays.pkl.gz\", \"rb\") as f:\n",
    "    networks = pickle.load(f)\n",
    "\n",
    "proj_head_mse_adhoc = torch.load(get_data_dir() / f\"proj_head_image_infonce.pt\", weights_only=False).cpu()\n",
    "proj_head_img = torch.load(get_data_dir() / f\"proj_head_image_infonce.pt\", weights_only=False).cpu()\n",
    "proj_head_text = torch.load(get_data_dir() / f\"proj_head_text_infonce.pt\", weights_only=False).cpu()\n",
    "specter = Specter(\"allenai/specter2_aug2023refresh\", adapter=\"adhoc_query\")\n",
    "autoencoder = torch.load(get_data_dir() / \"autoencoder_sparse.pt\", weights_only=False).cpu()\n",
    "# decoder = autoencoder.decoder.to(\"cpu\")\n",
    "mask_arrays = np.load(f\"{get_data_dir()}/mask.npz\", allow_pickle=True)\n",
    "mask_img = nib.Nifti1Image(mask_arrays[\"mask\"].astype(float),  mask_arrays[\"affine\"])\n",
    "masker = maskers.NiftiMasker(mask_img=mask_img, dtype=np.float32).fit()"
   ],
   "id": "d4abfe95c05637e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Network vs. articles",
   "id": "6f06c89c02ba4773"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:06:14.381126Z",
     "start_time": "2025-11-18T21:06:14.365940Z"
    }
   },
   "cell_type": "code",
   "source": "networks = {k: v for _k in networks.keys() for k, v in networks[_k].items()}",
   "id": "536d4627dac2b3e8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:06:19.048501Z",
     "start_time": "2025-11-18T21:06:15.507544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask_arrays = np.load(f\"{get_data_dir()}/mask.npz\", allow_pickle=True)\n",
    "mask_img = nib.Nifti1Image(mask_arrays[\"mask\"].astype(float),  mask_arrays[\"affine\"])\n",
    "masker = maskers.NiftiMasker(mask_img=mask_img, dtype=np.float32).fit()\n",
    "networks_resampled = {}\n",
    "\n",
    "for k in tqdm(networks.keys(), total=len(networks)):\n",
    "    img = nib.Nifti1Image(networks[k][\"array\"], affine=networks[k][\"affine\"])\n",
    "\n",
    "    if len(np.unique(networks[k][\"array\"])) == 2:\n",
    "        # binary data\n",
    "        img_resampled = resample_img(img, mask_arrays[\"affine\"], interpolation=\"nearest\")\n",
    "    else:\n",
    "        img_resampled = resample_img(img, mask_arrays[\"affine\"])\n",
    "        img_resampled_arr = img_resampled.get_fdata()\n",
    "        img_resampled_arr[img_resampled_arr < 0] = 0.\n",
    "        thresh = np.percentile(img_resampled_arr.flatten(), 95)\n",
    "        img_resampled_arr[img_resampled_arr < thresh] = 0.\n",
    "        img_resampled_arr[img_resampled_arr >= thresh] = 1.\n",
    "        img_resampled = nib.Nifti1Image(img_resampled_arr, affine=mask_arrays[\"affine\"])\n",
    "\n",
    "    networks_resampled[k] = img_resampled"
   ],
   "id": "61fa6063535d8d7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4887c09e943c4cbcbba7c3815d6fd863"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:06:55.136924Z",
     "start_time": "2025-11-18T21:06:30.550397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "networks_embed = {}\n",
    "\n",
    "for k, v in tqdm(networks_resampled.items(), total=len(networks_resampled)):\n",
    "    networks_embed[k] = autoencoder.encoder(torch.from_numpy(masker.transform(v)))"
   ],
   "id": "baa11f50fe612666",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ce2c0db51e449abb9d33c4f4480a28d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:08:41.886733Z",
     "start_time": "2025-11-18T21:08:41.881753Z"
    }
   },
   "cell_type": "code",
   "source": "networks_embed.keys()",
   "id": "7ab1b38ceff10ec6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['VIS-P', 'CG-OP', 'DN-B', 'SMOT-B', 'AUD', 'PM-PPr', 'dATN-B', 'SMOT-A', 'LANG', 'FPN-B', 'FPN-A', 'dATN-A', 'VIS-C', 'SAL/PMN', 'DN-A', 'NONE', 'Visual1', 'Visual2', 'Somatomotor', 'CingOperc', 'DorsAttn', 'Language', 'FrontPar', 'Auditory', 'Default', 'PostMulti', 'VentMulti', 'OrbitAffective', 'ICA1', 'ICA2', 'ICA3', 'ICA4', 'ICA5', 'ICA6', 'ICA7', 'ICA8', 'ICA9', 'ICA10', 'ICA11', 'ICA12', 'ICA13', 'ICA14', 'ICA15', 'ICA17', 'ICA18', 'ICA19', 'ICA20', 'ICA23', 'Emo/Interoception1', 'Emo/Interoception2', 'Emo/Interoception3', 'Emo/Interoception4', 'Mot/Visspatial1', 'Mot/Visspatial2', 'Mot/Visspatial3', 'Mot/Visspatial4', 'Visual3', 'DivergentCog1', 'DivergentCog3', 'DivergentCog4', 'DivergentCog5', 'DivergentCog6', 'medial frontal', 'frontoparietal', 'default mode', 'motor cortex', 'visual A', 'visual B', 'visual association', 'subcortical cerebellum', 'AntSal', 'DorsalDMN', 'HighVisual', 'LECN', 'PostSal', 'Precuneus', 'PrimVisual', 'RECN', 'Sensorimotor', 'VentralDMN', 'Visuospatial', 'ICA16', 'ICA21', 'LatVis', 'MedVis', 'Premotor', 'Salience', 'HandSM', 'FaceSM', 'AntMTL', 'PostMTL', 'ParMemory', 'Context', 'FootSM', 'Visual', 'VentAttn', 'DorsalSM', 'VentralSM', 'MedPar', 'ParOcc', 'SCAN', 'Cingulo-Opercular', 'Effector-hand', 'Effector-mouth', 'Effector-foot', 'SM', 'LateralSM', 'ResponseOneHanded(1RESP)', 'ResponseTwoHanded(2RESP)', 'AuditoryAttentionResponse(AAR)', 'AuditoryPrimarySensory(AUD)', 'DMNNovel(DMNA)', 'DMNTraditional(DMNB)', 'FocusOnVisualFeatures(FoVF)', 'Initiation(INIT)', 'Language(LN)', 'MAIN', 'MultipleDemand(MDN)', 'Re-evaluation(RE-EV)', 'DefaultA', 'DefaultB', 'DefaultC', 'ContA', 'ContB', 'ContC', 'SalVenAttnA', 'SalVenAttnB', 'DorsAttnA', 'DorsAttnB', 'Aud', 'SomMotA', 'SomMotB', 'VisualA', 'VisualB', 'VisualC', 'TempPar', 'LimbicA', 'LimbicB', 'SalVentAttnB', 'SalVentAttnA', 'VisPeri', 'VisCent', 'SomatomotorA', 'SomatomotorB', 'Sal/VenAttnA', 'Sal/VenAttnB', 'ControlC', 'ControlA', 'ControlB', 'Sal/VenAttn', 'Limbic', 'Control'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a7aa1906009b75d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
