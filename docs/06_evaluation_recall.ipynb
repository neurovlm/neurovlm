{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce28585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from neurovlm.data import get_data_dir\n",
    "from neurovlm.models import TextAligner\n",
    "from neurovlm.loss import InfoNCELoss, recall_n, mix_match\n",
    "from neurovlm.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4a90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuroVLM embeddings\n",
    "neurovlm_dir = get_data_dir()\n",
    "latent_text_specter, pmids_neurovlm = torch.load(neurovlm_dir / \"latent_specter2_neuro.pt\", weights_only=False).values()\n",
    "# latent_text_specter, pmids_neurovlm = torch.load(neurovlm_dir / \"latent_specter2_adhoc.pt\", weights_only=False).values()\n",
    "\n",
    "latent_neuro = torch.load(neurovlm_dir / \"latent_neuro.pt\")\n",
    "df = pd.read_parquet(neurovlm_dir / \"publications_more.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bad520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load NeuroConText pmids\n",
    "# data_dir = Path('/Users/ryanhammonds/projects/NeuroConText/data_NeuroConText')\n",
    "# train_pmids = np.array(list(pd.read_pickle(data_dir/ \"train_pmids.pkl\")))\n",
    "# test_pmids = np.array(list(pd.read_pickle(data_dir / \"test_pmids.pkl\")))\n",
    "# pmids = np.concatenate((train_pmids, test_pmids))\n",
    "# pmids = np.sort(pmids)\n",
    "# np.save(neurovlm_dir / \"pmids_neurocontext.npy\", pmids)\n",
    "\n",
    "pmids = np.load(neurovlm_dir / \"pmids_neurocontext.npy\")\n",
    "mask = np.array(df['pmid'].isin(pmids))\n",
    "latent_neuro = latent_neuro[mask]\n",
    "latent_text_specter = latent_text_specter[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa32dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch: -1, val loss: 6.9998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1309ea10604b4e78809f13257e646536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val loss: 6.9417\n",
      "Epoch: 10, val loss: 6.6846\n",
      "Epoch: 20, val loss: 6.5093\n",
      "Epoch: 30, val loss: 6.3507\n",
      "Epoch: 40, val loss: 6.283\n",
      "Epoch: 50, val loss: 6.2361\n",
      "Epoch: 60, val loss: 6.1974\n",
      "Epoch: 70, val loss: 6.1777\n",
      "Epoch: 80, val loss: 6.1638\n",
      "Epoch: 90, val loss: 6.1399\n",
      "Epoch: 100, val loss: 6.1311\n",
      "Epoch: 110, val loss: 6.121\n",
      "Epoch: 120, val loss: 6.1107\n",
      "Epoch: 130, val loss: 6.1072\n",
      "Epoch: 140, val loss: 6.1002\n",
      "Epoch: 150, val loss: 6.0958\n",
      "Epoch: 160, val loss: 6.0958\n",
      "Epoch: 170, val loss: 6.0889\n",
      "Epoch: 180, val loss: 6.0906\n",
      "Epoch: 190, val loss: 6.0854\n",
      "Epoch: 200, val loss: 6.0942\n",
      "Epoch: 210, val loss: 6.0899\n",
      "Epoch: 220, val loss: 6.0878\n",
      "Epoch: 230, val loss: 6.0903\n",
      "Epoch: 240, val loss: 6.0976\n",
      "Epoch: 250, val loss: 6.0864\n",
      "Epoch: 260, val loss: 6.0891\n",
      "Epoch: 270, val loss: 6.0924\n",
      "Epoch: 280, val loss: 6.0911\n",
      "Epoch: 290, val loss: 6.0951\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "recall_fn = partial(recall_n, thresh=0.95, reduce_mean=True)\n",
    "perf_20_nv = np.zeros(10)   # recall@20\n",
    "perf_200_nv = np.zeros(10)  # recall@200\n",
    "mix_match_nv = np.zeros(10)\n",
    "\n",
    "# CV\n",
    "n_epochs_nv = 300\n",
    "val_size = 1000\n",
    "kfolds = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "\n",
    "for i, (inds_train, inds_test) in enumerate(kfolds.split(np.arange(len(latent_neuro)))):\n",
    "\n",
    "    print(f\"Fold: {i}\")\n",
    "\n",
    "    # Data loaders and output directory\n",
    "    fold_dir = neurovlm_dir / \"models\" / \"tmp\"\n",
    "    fold_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.random.seed(i)\n",
    "    np.random.shuffle(inds_train)\n",
    "\n",
    "    inds_val = inds_train[:val_size]\n",
    "    inds_train = inds_train[val_size:]\n",
    "\n",
    "    # Projection head (align latent text to latent neuro)\n",
    "    trainer_specter = Trainer(\n",
    "        TextAligner(seed=i),\n",
    "        batch_size=int(4098),\n",
    "        n_epochs=n_epochs_nv,\n",
    "        lr=4e-5,\n",
    "        loss_fn=InfoNCELoss(),\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        X_val=latent_text_specter[inds_val],\n",
    "        y_val=latent_neuro[inds_val],\n",
    "        device=\"auto\",\n",
    "        verbose=True,\n",
    "        interval=10,\n",
    "        use_tqdm=True\n",
    "    )\n",
    "\n",
    "    trainer_specter.fit(\n",
    "        latent_text_specter[inds_train].clone(),\n",
    "        latent_neuro[inds_train].clone()\n",
    "    )\n",
    "    trainer_specter.restore_best() # restore model with best val loss\n",
    "    proj_head = trainer_specter.model.to(\"cpu\")\n",
    "    trainer_specter.save(fold_dir / \"proj_head.pt\")\n",
    "\n",
    "    # Performance\n",
    "    with torch.no_grad():\n",
    "        # Neurovlm\n",
    "        image_embeddings_nv = latent_neuro[inds_test].to(\"cpu\").detach().clone()\n",
    "        text_embeddings_nv = proj_head(latent_text_specter[inds_test]).detach()\n",
    "        # Norm for cosine similarity\n",
    "        image_embeddings_nv /= image_embeddings_nv.norm(dim=1)[:, None]\n",
    "        text_embeddings_nv /= text_embeddings_nv.norm(dim=1)[:, None]\n",
    "\n",
    "    # Neurovlm\n",
    "    similarity = (image_embeddings_nv @ text_embeddings_nv.T).softmax(dim=1).numpy()\n",
    "    perf_20_nv[i] = recall_fn(similarity, np.eye(len(similarity)), n_first=20)\n",
    "    perf_200_nv[i] = recall_fn(similarity, np.eye(len(similarity)), n_first=200)\n",
    "    mix_match_nv[i] = mix_match(similarity)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be338e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurovlm</th>\n",
       "      <th>neurocontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall@20</th>\n",
       "      <td>0.135880</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@200</th>\n",
       "      <td>0.469536</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mix&amp;match</th>\n",
       "      <td>0.796885</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            neurovlm  neurocontext\n",
       "recall@20   0.135880         0.218\n",
       "recall@200  0.469536         0.596\n",
       "mix&match   0.796885         0.848"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"neurovlm\": [perf_20_nv[i], perf_200_nv[i], mix_match_nv[i]],\n",
    "    \"neurocontext\": [0.218, 0.596, 0.848] # from neurocontext model & dataset\n",
    "}, index=[\"recall@20\", \"recall@200\", \"mix&match\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
