{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn.image import resample_to_img, threshold_img\n",
    "\n",
    "from neurovlm.models import Specter\n",
    "from neurovlm.data import data_dir, load_masker, load_dataset\n",
    "from neurovlm.train import which_device\n",
    "masker = load_masker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b5de86",
   "metadata": {},
   "source": [
    "# Neurovault\n",
    "\n",
    "This notebook fetches and processes neurovault data. This notebook is slow since it fetches lots of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ba0e9",
   "metadata": {},
   "source": [
    "## Fetch\n",
    "Pull images and metadata from neurovault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescrape = False\n",
    "\n",
    "if rescrape:\n",
    "\n",
    "    # Scrape neurovault, this is slow\n",
    "    db = []\n",
    "    offsets = list(range(0, 16000, 100))\n",
    "    for i in tqdm(offsets, total=len(offsets)):\n",
    "        pg = requests.get(f\"https://neurovault.org/api/collections/?offset={str(i)}\")\n",
    "        db.append(pg)\n",
    "\n",
    "    db_json = [i.json() for i in db]\n",
    "    out = [j for i in db_json for j in i[\"results\"]]\n",
    "    filtered_out = [i for i in out if i[\"number_of_images\"] > 0 and i[\"DOI\"] is not None]\n",
    "\n",
    "    with open(data_dir / \"neurovault_collections.pkl\", \"wb\") as f:\n",
    "        pickle.dump(filtered_out, f)\n",
    "\n",
    "    meta_images = []\n",
    "    for i in tqdm(filtered_out, total=len(filtered_out)):\n",
    "        meta_images.extend(\n",
    "            requests.get(f\"https://neurovault.org/api/collections/{str(i['id'])}/images/\").json()[\"results\"]\n",
    "        )\n",
    "\n",
    "    with open(data_dir / \"neurovault_images.pkl\", \"wb\") as f:\n",
    "        pickle.dump(meta_images, f)\n",
    "\n",
    "    # Preprocess\n",
    "    df_collections = pd.DataFrame(filtered_out)\n",
    "\n",
    "    df_images = pd.DataFrame(meta_images)\n",
    "    df_images = df_images.iloc[:, :67]\n",
    "    df_images = df_images[(df_images[\"analysis_level\"] == \"group\")]\n",
    "    df_images = df_images.drop_duplicates(\"id\")\n",
    "\n",
    "    df_collections = df_collections[df_collections['id'].isin(df_images['collection_id'])]\n",
    "    df_collections.to_parquet(data_dir / \"neurovault_collections.parquet\")\n",
    "    df_images.to_parquet(data_dir / \"neurovault_images.parquet\")\n",
    "\n",
    "    # Scrape abstracts from crossref\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "\n",
    "    for doi in tqdm(df_collections[\"DOI\"], total=len(df_collections)):\n",
    "\n",
    "        url = f\"https://api.crossref.org/works/{doi}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        title = data['message']['title'][0]\n",
    "        abstract = data['message'].get('abstract', 'No abstract available')\n",
    "\n",
    "        titles.append(title)\n",
    "        abstracts.append(abstract)\n",
    "\n",
    "    df_text = pd.DataFrame(dict(\n",
    "        doi=df_collections[\"DOI\"],\n",
    "        title=titles,\n",
    "        abstract=abstracts,\n",
    "    ))\n",
    "    df_text[\"abstract\"] = df_text[\"abstract\"].replace(\"No abstract available\", pd.NA)\n",
    "    df_text.to_parquet(data_dir / \"neurovault_abstracts.parquet\")\n",
    "else:\n",
    "    # Skip scraping\n",
    "    df_collections = pd.read_parquet(data_dir / \"neurovault_collections.parquet\")\n",
    "    df_images = pd.read_parquet(data_dir / \"neurovault_images.parquet\")\n",
    "    df_text = pd.read_parquet(data_dir / \"neurovault_abstracts.parquet\")    # scaped from crossref\n",
    "    df_missing = pd.read_csv(data_dir / \"neurovault_abstracts_missing.csv\") # manually scraped, missing from crossref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af188133",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be67330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_abstracts(df_abstracts):\n",
    "    \"\"\"Regex to clean up noisy abstract formats.\"\"\"\n",
    "\n",
    "    # Reduce white spcae, newlines, tabs\n",
    "    df_abstracts['abstract'] = df_abstracts[\"abstract\"].str.replace(r'</?[^>]+?>', '', regex=True)\n",
    "    df_abstracts['abstract'] = df_abstracts['abstract'].str.replace(\"\\n\", \" \")\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r'\\s+', ' ', regex=True)\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.strip(\" \")\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.strip(\"\\t\")\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r\"^ \", \"\", regex=True)\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r\"^\\t\", \"\", regex=True)\n",
    "\n",
    "    # Remove headers\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r\"^Abstract\\s*\", \"\", regex=True)\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r\"^ABSTRACT\\s*\", \"\", regex=True)\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r\"^Significance\\s*\", \"\", regex=True)\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r\"^Background\\s*\", \"\", regex=True)\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(r\"^Objective\\s*\", \"\", regex=True)\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(\"BACKGROUND AND OBJECTIVES: \", \"\")\n",
    "\n",
    "    # Special characters\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(\"( \", \"(\").replace(\" )\", \")\")\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(\"â€™\", \"'\")\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(\"&amp\", \"&\")\n",
    "    df_abstracts[\"abstract\"] = df_abstracts[\"abstract\"].str.replace(\"&lt;b&gt;&lt;i&gt;Introduction:&lt;/i&gt;&lt;/b&gt; \", \"\")\n",
    "\n",
    "    return df_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dabf273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "df_text = clean_abstracts(df_text)\n",
    "df_missing = clean_abstracts(df_missing)\n",
    "df_missing = df_missing.merge(\n",
    "    df_collections[[\"DOI\", \"name\"]].rename(columns={\"DOI\":\"doi\", \"name\":\"title\"}), on=\"doi\", how=\"left\"\n",
    ")\n",
    "df_pubs = pd.concat((df_text, df_missing))\n",
    "df_pubs.to_parquet(data_dir / \"neurovault_publications.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd9edc",
   "metadata": {},
   "source": [
    "## Images\n",
    "\n",
    "1. Resample images to a common space.\n",
    "2. Cluster threshold activation maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487f0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "df_collections = pd.read_parquet(data_dir / \"neurovault_collections.parquet\")\n",
    "df_collections = df_collections.rename(columns=dict(id=\"collection_id\"))\n",
    "\n",
    "df_images = pd.read_parquet(data_dir / \"neurovault_images.parquet\")\n",
    "df_images = df_images[df_images[\"is_thresholded\"] == False]\n",
    "df_images = df_images[~df_images[\"id\"].isin([22136, 22137, 22138])] # these ids are missing images\n",
    "df_images = df_images[~(df_images[\"map_type\"].isin(['parcellation', 'anatomical', \"ROI/mask\", \"variance\"]))]\n",
    "\n",
    "df = df_images[[\"id\", \"collection_id\", 'contrast_definition']].merge(\n",
    "    df_collections[[\"name\", \"collection_id\"]], on=\"collection_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd41374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b84e40286084733a037bc210584dd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masker = load_masker()\n",
    "\n",
    "def process_one(idx, img_id):\n",
    "    \"\"\"Define worker.\"\"\"\n",
    "    f = data_dir / \"neurovault_images\" / f\"neurovault_img_{img_id}.nii.gz\"\n",
    "\n",
    "    try:\n",
    "        img = nib.load(f)\n",
    "\n",
    "        # some maps have nan for outside of brain\n",
    "        img_arr = img.get_fdata()\n",
    "        mask = ~np.isfinite(img_arr)\n",
    "        if np.all(mask):\n",
    "            print(f\"All NaN: {img_id}\")\n",
    "        img_arr[mask] = 0\n",
    "\n",
    "        # needs to be continuous, not binary or integer\n",
    "        if len(np.unique(img_arr.flatten())) < 10:\n",
    "            return idx, None\n",
    "\n",
    "        # resample\n",
    "        img = nib.Nifti1Image(img_arr, img.affine)\n",
    "        arr = masker.transform(\n",
    "            resample_to_img(img, masker.mask_img, interpolation=\"nearest\",\n",
    "            force_resample=True, copy_header=True\n",
    "        ))\n",
    "\n",
    "        arr[arr < 0] = 0\n",
    "        # arr = np.abs(arr)\n",
    "    except:\n",
    "        # catch all because these are abitrary user uploaded files,\n",
    "        # there is no clean way to guarantee valid nii.gz images\n",
    "        return idx, None\n",
    "\n",
    "    return idx, arr\n",
    "\n",
    "# Setup\n",
    "n = len(df)\n",
    "neuro = torch.zeros((n, 28542), dtype=torch.float32)\n",
    "\n",
    "# Process images in parallel\n",
    "results = Parallel(n_jobs=16, backend=\"loky\", prefer=\"processes\")(\n",
    "    delayed(process_one)(idx, img_id)\n",
    "    for idx, img_id in enumerate(tqdm(df[\"id\"].copy(), total=n))\n",
    ")\n",
    "\n",
    "# Re-order\n",
    "neuro = torch.zeros((n, 28542), dtype=torch.float32)\n",
    "for idx, arr in results:\n",
    "    if arr is not None:\n",
    "        neuro[idx] = torch.from_numpy(arr)\n",
    "\n",
    "torch.save(neuro, \"neuro.pt\")\n",
    "df.to_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c2a323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4553, 5), torch.Size([4553, 28542]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuro = torch.load(\"neuro.pt\")\n",
    "df = pd.read_csv(\"df.csv\")\n",
    "\n",
    "# Drop empty (unthresholded map is empty) and binary maps\n",
    "mask = ~((neuro == 0).all(axis=1)).numpy()\n",
    "df, neuro = df[mask], neuro[mask]\n",
    "\n",
    "mask = np.array([len(np.unique(i)) > 50 for i in neuro])\n",
    "df, neuro = df[mask], neuro[mask]\n",
    "df.shape, neuro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2db4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcabc2965d74446593b119150a5c02d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4553 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cluster activation maps\n",
    "def cluster(i, arr):\n",
    "    thr_img = threshold_img(\n",
    "        masker.inverse_transform(arr), \"99%\",\n",
    "        cluster_threshold=50, two_sided=False, copy_header=True\n",
    "    )\n",
    "    vec = masker.transform(thr_img)\n",
    "    return i, vec.astype(np.float32, copy=False)\n",
    "\n",
    "neuro_cp = neuro.detach().cpu().numpy()\n",
    "neuro_cp[neuro_cp < 0] = 0\n",
    "\n",
    "results = Parallel(n_jobs=16, backend=\"loky\")(\n",
    "    delayed(cluster)(i, arr) for i, arr in\n",
    "    enumerate(tqdm(neuro_cp, total=len(neuro_cp)))\n",
    ")\n",
    "\n",
    "neuro_clustered = np.zeros((len(neuro), 28542), dtype=np.float32)\n",
    "for i, vec in results:\n",
    "    neuro_clustered[i] = vec\n",
    "\n",
    "np.save(\"neuro_clustered.npy\", neuro_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188beb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro_clustered = np.load(\"neuro_clustered.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97f76f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop overactive examples (whole brain is activated)\n",
    "mask = (neuro_clustered != 0).mean(axis=1) < 0.1\n",
    "df = df[mask]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "neuro_clustered = neuro_clustered[mask]\n",
    "neuro = neuro[mask]\n",
    "\n",
    "# Drop all zero\n",
    "mask = ~(neuro_clustered == 0).all(axis=1)\n",
    "neuro_clustered = neuro_clustered[mask]\n",
    "neuro = neuro[mask]\n",
    "df = df[mask]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac068dd",
   "metadata": {},
   "source": [
    "## Filter\n",
    "\n",
    "Remove pubmed training ids from this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pubmed = load_dataset(\"publications\")\n",
    "\n",
    "df_collections_filt = df_collections[\n",
    "    df_collections[\"collection_id\"].isin(df['collection_id'].unique())\n",
    "]\n",
    "\n",
    "df_collections_filt = df_collections_filt[\n",
    "    ~(df_collections_filt[\"DOI\"].isin(df_pubmed[\"doi\"]))\n",
    "]\n",
    "\n",
    "# Drop\n",
    "mask = df[\"collection_id\"].isin(df_collections_filt[\"collection_id\"])\n",
    "df = df[mask]\n",
    "neuro = neuro[mask]\n",
    "neuro_clustered = neuro_clustered[mask]\n",
    "\n",
    "df_pubs = pd.read_parquet(data_dir / \"neurovault_publications.parquet\")\n",
    "df_pubs = df_pubs[df_pubs[\"doi\"].isin(\n",
    "    df_collections_filt[df_collections_filt[\"collection_id\"].isin(\n",
    "        df[\"collection_id\"]\n",
    "    )][\"DOI\"]\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55423018",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neuro_clustered, data_dir / \"neuro_clust.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e587c33",
   "metadata": {},
   "source": [
    "## Encode Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859f4fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3409f4935554422a980e74c4cf8ba3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specter = Specter(\n",
    "    model=\"allenai/specter2_aug2023refresh\",\n",
    "    adapter=\"adhoc_query\",\n",
    "    device=which_device()\n",
    ")\n",
    "\n",
    "titles = df_pubs[\"title\"]\n",
    "abstracts = df_pubs[\"abstract\"]\n",
    "\n",
    "batch_size = 64\n",
    "text_emb_titles = torch.zeros((len(titles), 768))\n",
    "text_emb_abstracts = torch.zeros((len(titles), 768))\n",
    "text_emb_titles_abstracts = torch.zeros((len(titles), 768))\n",
    "\n",
    "for i in tqdm(range(0, len(titles), batch_size), total=len(titles)//batch_size):\n",
    "    with torch.no_grad():\n",
    "        text_emb_titles[i:i+batch_size] = specter(titles[i:i+batch_size].tolist()).detach()\n",
    "        text_emb_abstracts[i:i+batch_size] = specter(abstracts[i:i+batch_size].tolist()).detach()\n",
    "        text_emb_titles_abstracts[i:i+batch_size] = specter(\n",
    "            (titles[i:i+batch_size] + \"[SEP]\" + abstracts[i:i+batch_size]).tolist()\n",
    "        ).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "031f6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"df_neuro\": df.merge(\n",
    "        df_collections_filt[[\"collection_id\", \"DOI\"]].rename(\n",
    "            columns={\"DOI\": \"doi\"}\n",
    "        ),\n",
    "        on=\"collection_id\", how=\"left\"\n",
    "    ),\n",
    "    \"df_pubs\": df_pubs,\n",
    "    \"neuro\": neuro,\n",
    "    \"neuro_clustered\": neuro_clustered,\n",
    "    \"text_emb_titles\": text_emb_titles,\n",
    "    \"text_emb_abstracts\": text_emb_abstracts,\n",
    "    \"text_emb_titles_abstracts\": text_emb_titles_abstracts\n",
    "}, data_dir / \"neurovault.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
