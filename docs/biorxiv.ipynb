{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c883c37-815c-4668-ac67-1ef896f80c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\amola\\anaconda3\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\amola\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\amola\\anaconda3\\lib\\site-packages (0.11.6)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\amola\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.21)\n",
      "Requirement already satisfied: camelot-py[cv] in c:\\users\\amola\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (8.1.7)\n",
      "Requirement already satisfied: chardet>=5.1.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.26.1 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (1.26.4)\n",
      "Requirement already satisfied: openpyxl>=3.1.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (3.1.5)\n",
      "Requirement already satisfied: pdfminer-six>=20240706 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (20250327)\n",
      "Requirement already satisfied: pypdf<6.0,>=4.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (5.5.0)\n",
      "Requirement already satisfied: pandas>=2.2.2 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (2.2.2)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (0.9.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (4.11.0.86)\n",
      "Requirement already satisfied: pypdfium2>=4 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (4.30.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\amola\\anaconda3\\lib\\site-packages (from click>=8.0.1->camelot-py[cv]) (0.4.6)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\amola\\anaconda3\\lib\\site-packages (from openpyxl>=3.1.0->camelot-py[cv]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pandas>=2.2.2->camelot-py[cv]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pandas>=2.2.2->camelot-py[cv]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pandas>=2.2.2->camelot-py[cv]) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pdfminer-six>=20240706->camelot-py[cv]) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from pdfminer-six>=20240706->camelot-py[cv]) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (1.17.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amola\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2.2->camelot-py[cv]) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\amola\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (2.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: camelot-py 1.0.0 does not provide the extra 'cv'\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "!pip install PyPDF2\n",
    "!pip install pdfplumber\n",
    "!pip install \"camelot-py[cv]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e83ed2d-4f99-43fd-9793-dd79fe047271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          DOI  Page   x   y   z\n",
      "0   10.1101/2025.02.10.636597    17  56 -14   6\n",
      "1   10.1101/2025.02.10.636597    17 -54 -28  10\n",
      "2   10.1101/2025.02.10.636597    17  -6   8  54\n",
      "3   10.1101/2025.02.10.636597    17 -40  18  60\n",
      "4   10.1101/2025.02.10.636597    17   6  10  58\n",
      "5   10.1101/2025.02.10.636597    17  72 -52 -32\n",
      "6   10.1101/2025.02.10.636597    17  16 -56   6\n",
      "7   10.1101/2025.02.10.636597    17  14  52  10\n",
      "8   10.1101/2025.02.10.636597    17   7 -28  -6\n",
      "9   10.1101/2025.02.10.636597    17   5  20 -52\n",
      "10  10.1101/2025.02.10.636597    18  58  30  24\n",
      "11  10.1101/2025.02.10.636597    18  30  46  40\n",
      "12  10.1101/2025.02.10.636597    18  43 -32  20\n",
      "13  10.1101/2025.02.10.636597    18   6 -44   2\n",
      "14  10.1101/2025.02.10.636597    18  13 -30 -64\n",
      "15  10.1101/2025.02.10.636597    18  11  34 -62\n",
      "16  10.1101/2025.02.10.636597    20  44  42   6\n",
      "17  10.1101/2025.02.10.636597    20 -28 -72 -28\n",
      "18  10.1101/2025.02.10.636597    20  56 -40  48\n",
      "19  10.1101/2025.02.10.636597    20  54  10  14\n",
      "20  10.1101/2025.02.10.636597    20 -58 -34  44\n",
      "21  10.1101/2025.02.10.636597    20  67 -40  -4\n",
      "22  10.1101/2025.02.10.636597    20  59  40  48\n",
      "23  10.1101/2025.02.10.636597    20  65  40   0\n",
      "24  10.1101/2025.02.10.636597    20 -42  52   4\n",
      "25  10.1101/2025.02.10.636597    20  38 -70 -42\n",
      "26  10.1101/2025.02.10.636597    20  11  56 -24\n",
      "27  10.1101/2025.02.10.636597    20  10 -26  44\n",
      "28  10.1101/2025.02.10.636597    20  54 -44 -64\n",
      "29  10.1101/2025.02.10.636597    20  16   4  26\n",
      "30  10.1101/2025.02.10.636597    20  45   6 -34\n",
      "31  10.1101/2025.02.10.636597    20  11  16  60\n",
      "32  10.1101/2025.02.10.636597    20   7  46  -2\n",
      "33  10.1101/2025.02.10.636597    20   9  22  12\n",
      "34  10.1101/2025.02.10.636597    20  17 -36  30\n",
      "35  10.1101/2025.02.10.636597    20   6 -38 -16\n",
      "36  10.1101/2025.02.10.636597    20   6  44  26\n",
      "37  10.1101/2025.02.10.636597    20   7 -42  42\n",
      "38  10.1101/2025.02.10.636597    22 -50 -22  50\n",
      "39  10.1101/2025.02.10.636597    22  69  60 -32\n",
      "40  10.1101/2025.02.10.636597    22  45  46  48\n",
      "41  10.1101/2025.02.10.636597    22  48  40 -26\n",
      "42  10.1101/2025.02.10.636597    23  17 -32  12\n",
      "43  10.1101/2025.02.10.636597    23  43  54 -14\n",
      "44  10.1101/2025.02.10.636597    23  12  62 -26\n",
      "45  10.1101/2025.02.10.636597    23  16  -2 -32\n",
      "46  10.1101/2025.02.10.636597    23   5  52  -2\n",
      "47  10.1101/2025.02.10.636597    23  19   2 -34\n"
     ]
    }
   ],
   "source": [
    "#Paper 1- simply extracting coordinates from table (this code is pretty paper speific)\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import requests\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_tables(file_path: str, page: str | int):\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
    "            return camelot.read_pdf(file_path, pages=str(page), flavor=\"stream\")\n",
    "\n",
    "def extract_mni_coordinates_from_table(table_df: pd.DataFrame):\n",
    "    mni_data = []\n",
    "    for _, row in table_df.iterrows():\n",
    "        row = row.dropna().tolist()\n",
    "        # Trying to find the coordinates\n",
    "        for i in range(len(row) - 2):\n",
    "            try:\n",
    "                x, y, z = int(row[i]), int(row[i+1]), int(row[i+2])\n",
    "                # These are the values within rough brain coordinate bounds\n",
    "                if all(-100 < val < 100 for val in (x, y, z)):\n",
    "                    mni_data.append((x, y, z))\n",
    "                    break  # To prevent double counting\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return mni_data\n",
    "\n",
    "# Paper 1\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2025.02.10.636597v2.full.pdf\"\n",
    "doi = \"10.1101/2025.02.10.636597\"\n",
    "file_path = \"paper1_fixed.pdf\"\n",
    "\n",
    "# Download PDF\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "results = []\n",
    "for page in range(1, 31):\n",
    "    try:\n",
    "        tables = read_tables(file_path, page)\n",
    "        for table in tables:\n",
    "            coords = extract_mni_coordinates_from_table(table.df)\n",
    "            for x, y, z in coords:\n",
    "                results.append({\n",
    "                    \"DOI\": doi,\n",
    "                    \"Page\": page,\n",
    "                    \"x\": x,\n",
    "                    \"y\": y,\n",
    "                    \"z\": z\n",
    "                })\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "df1 = pd.DataFrame(results)\n",
    "if not df1.empty:\n",
    "    print(df1)\n",
    "else:\n",
    "    print(\"No correct MNI coordinates found in this paper.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba38b35-2fda-4737-b7a8-3040e005ac19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          DOI  Page   x   y   z\n",
      "0   10.1101/2024.11.20.624446     4 -45   0  45\n",
      "1   10.1101/2024.11.20.624446     4   9  13 -45\n",
      "2   10.1101/2024.11.20.624446     4  43  36 -63\n",
      "3   10.1101/2024.11.20.624446     4  44  83 -51\n",
      "4   10.1101/2024.11.20.624446     4  45  56 -45\n",
      "5   10.1101/2024.11.20.624446     4 -42  15  -3\n",
      "6   10.1101/2024.11.20.624446     4   6  94  42\n",
      "7   10.1101/2024.11.20.624446     4   9   5  45\n",
      "8   10.1101/2024.11.20.624446     4  43  33  60\n",
      "9   10.1101/2024.11.20.624446     4  44  90  48\n",
      "10  10.1101/2024.11.20.624446     4  45  95  45\n",
      "11  10.1101/2024.11.20.624446     4  39  18   0\n",
      "12  10.1101/2024.11.20.624446     5 -45   0  45\n",
      "13  10.1101/2024.11.20.624446     5  42   6  57\n",
      "14  10.1101/2024.11.20.624446     5 -45   9  45\n",
      "15  10.1101/2024.11.20.624446     5  45  15  54\n",
      "16  10.1101/2024.11.20.624446     5 -63   0  24\n",
      "17  10.1101/2024.11.20.624446     5  60  -3  24\n",
      "18  10.1101/2024.11.20.624446     5 -51   9  27\n",
      "19  10.1101/2024.11.20.624446     5  48  27  33\n",
      "20  10.1101/2024.11.20.624446     5 -45  39  21\n",
      "21  10.1101/2024.11.20.624446     5  45  30  18\n",
      "22  10.1101/2024.11.20.624446     5 -42  15  -3\n",
      "23  10.1101/2024.11.20.624446     5  39  18   0\n",
      "24  10.1101/2024.11.20.624446    17   1   8 -63\n",
      "25  10.1101/2024.11.20.624446    17   2  11 -48\n",
      "26  10.1101/2024.11.20.624446    17   3  13 -42\n",
      "27  10.1101/2024.11.20.624446    17   4  47 -45\n",
      "28  10.1101/2024.11.20.624446    17 -45   0  45\n",
      "29  10.1101/2024.11.20.624446    17   7   8 -33\n",
      "30  10.1101/2024.11.20.624446    17   8   8  -3\n",
      "31  10.1101/2024.11.20.624446    17   9  13 -45\n",
      "32  10.1101/2024.11.20.624446    17  10   9 -30\n",
      "33  10.1101/2024.11.20.624446    17  24  18  21\n",
      "34  10.1101/2024.11.20.624446    17  20   7 -39\n",
      "35  10.1101/2024.11.20.624446    17  21  15 -42\n",
      "36  10.1101/2024.11.20.624446    17  22  14 -66\n",
      "37  10.1101/2024.11.20.624446    17  24  40  -6\n",
      "38  10.1101/2024.11.20.624446    17  25  12  -6\n",
      "39  10.1101/2024.11.20.624446    18  27   2  -6\n",
      "40  10.1101/2024.11.20.624446    18  30  10 -12\n",
      "41  10.1101/2024.11.20.624446    18  32  62 -12\n",
      "42  10.1101/2024.11.20.624446    18  34  20 -24\n",
      "43  10.1101/2024.11.20.624446    18  36   4 -39\n",
      "44  10.1101/2024.11.20.624446    18  15  30 -27\n",
      "45  10.1101/2024.11.20.624446    18  38  59 -39\n",
      "46  10.1101/2024.11.20.624446    18  40  23 -54\n",
      "47  10.1101/2024.11.20.624446    18   2  42 -30\n",
      "48  10.1101/2024.11.20.624446    18  42  19 -63\n",
      "49  10.1101/2024.11.20.624446    18  43  36 -63\n",
      "50  10.1101/2024.11.20.624446    18  44  83 -51\n",
      "51  10.1101/2024.11.20.624446    18  45  56 -45\n",
      "52  10.1101/2024.11.20.624446    18  46  67 -30\n",
      "53  10.1101/2024.11.20.624446    18 -39  21  -6\n",
      "54  10.1101/2024.11.20.624446    18 -42  15  -3\n"
     ]
    }
   ],
   "source": [
    "#Paper 2 simply extracting coordinates from table (this code is also pretty paper speific)\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import requests\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_tables(file_path: str, page: str | int):\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
    "            return camelot.read_pdf(file_path, pages=str(page), flavor=\"stream\")\n",
    "\n",
    "def extract_mni_coordinates_from_table(table_df: pd.DataFrame):\n",
    "    mni_data = []\n",
    "    for _, row in table_df.iterrows():\n",
    "        row = row.dropna().tolist()\n",
    "        # Checking for 3 consecutive numeric values in row (neglecting the voxel count)\n",
    "        for i in range(len(row) - 2):\n",
    "            try:\n",
    "                x, y, z = int(row[i]), int(row[i+1]), int(row[i+2])\n",
    "                if all(-100 < val < 100 for val in (x, y, z)):\n",
    "                    mni_data.append((x, y, z))\n",
    "                    break  \n",
    "            except ValueError:\n",
    "                continue\n",
    "    return mni_data\n",
    "\n",
    "# Paper 2 Info\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2024.11.20.624446v2.full.pdf\"\n",
    "doi = \"10.1101/2024.11.20.624446\"\n",
    "file_path = \"paper2.pdf\"\n",
    "\n",
    "# Download PDF\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extracting MNI coordinates\n",
    "results = []\n",
    "for page in range(1, 21):\n",
    "    try:\n",
    "        tables = read_tables(file_path, page)\n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                coords = extract_mni_coordinates_from_table(table.df)\n",
    "                for x, y, z in coords:\n",
    "                    results.append({\n",
    "                        \"DOI\": doi,\n",
    "                        \"Page\": page,\n",
    "                        \"x\": x,\n",
    "                        \"y\": y,\n",
    "                        \"z\": z\n",
    "                    })\n",
    "    except Exception as e:\n",
    "        print(f\"Page {page} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# Output\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No MNI coordinates found in this paper.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1558e08f-1fc7-416c-8111-dcef74cd6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          DOI  Page   x   y   z\n",
      "0   10.1101/2024.11.20.624569     9 -20   1 -34\n",
      "1   10.1101/2024.11.20.624569     9 -28   3 -38\n",
      "2   10.1101/2024.11.20.624569     9 -28  -2 -42\n",
      "3   10.1101/2024.11.20.624569    10  27 -10 -28\n",
      "4   10.1101/2024.11.20.624569    12   7  47  23\n",
      "5   10.1101/2024.11.20.624569    12   5  57  -2\n",
      "6   10.1101/2024.11.20.624569    12   0  33  11\n",
      "7   10.1101/2024.11.20.624569    15  19 -10 -32\n",
      "8   10.1101/2024.11.20.624569    15  -4  21  -6\n",
      "9   10.1101/2024.11.20.624569    15  15  21 -26\n",
      "10  10.1101/2024.11.20.624569    15   1 -44  27\n",
      "11  10.1101/2024.11.20.624569    15  29   0 -42\n",
      "12  10.1101/2024.11.20.624569    17  -8  55   3\n",
      "13  10.1101/2024.11.20.624569    17  -4  39  -9\n",
      "14  10.1101/2024.11.20.624569    17   3  33 -12\n",
      "15  10.1101/2024.11.20.624569    86 -17   9 -12\n",
      "16  10.1101/2024.11.20.624569    86  26   0 -16\n",
      "17  10.1101/2024.11.20.624569    88   9  48  25\n"
     ]
    }
   ],
   "source": [
    "#Paper 3\n",
    "'''This code tries to extract coordinates from a research paper when the coordinatres are not in tabular form,\n",
    "and are inside paragraphs, but in the specific format- [x,y,z]'''\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "# Paper 3 Info\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2024.11.20.624569v2.full.pdf\"\n",
    "doi = \"10.1101/2024.11.20.624569\"\n",
    "file_path = \"paper3.pdf\"\n",
    "\n",
    "# Download the PDF\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# A regular expression pattern to find the coordinates in the form [x,y,z]\n",
    "mni_pattern = re.compile(r'\\[\\s*(-?\\d{1,3})\\s*,\\s*(-?\\d{1,3})\\s*,\\s*(-?\\d{1,3})\\s*\\]')\n",
    "\n",
    "results = []\n",
    "\n",
    "doc = fitz.open(file_path)\n",
    "for page_num in range(len(doc)):\n",
    "    text = doc[page_num].get_text()\n",
    "    matches = mni_pattern.findall(text)\n",
    "    \n",
    "    for match in matches:\n",
    "        x, y, z = map(int, match)\n",
    "        # Valid MNI range and meaningful values\n",
    "        if all(-100 <= val <= 100 for val in (x, y, z)):\n",
    "            results.append({\n",
    "                \"DOI\": doi,\n",
    "                \"Page\": page_num + 1,\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"z\": z\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No valid MNI coordinates found in the paper.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171bdda4-b20a-4cb5-8b00-2793fb959801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         DOI  Page   x   y   z\n",
      "0  10.1101/2025.04.04.647211    15 -44 -18  54\n",
      "1  10.1101/2025.04.04.647211    15 -38   8  48\n",
      "2  10.1101/2025.04.04.647211    15   8 -10  76\n",
      "3  10.1101/2025.04.04.647211    15 -44 -18  54\n",
      "4  10.1101/2025.04.04.647211    15 -38   8  48\n",
      "5  10.1101/2025.04.04.647211    16   6 -10  74\n",
      "6  10.1101/2025.04.04.647211    16  38 -38  62\n",
      "7  10.1101/2025.04.04.647211    18 -62 -18  34\n"
     ]
    }
   ],
   "source": [
    "#Paper 4: # This paper has tabular coodinates but in a very weird format so extracting coordinates from them was hard.\n",
    "#So this code needs more correcting because it is not yet recognizing all the tables in it, but it's working to some extent.\n",
    "\n",
    "import requests\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import contextlib\n",
    "\n",
    "# Suppress CropBox / MediaBox warnings\n",
    "@contextlib.contextmanager\n",
    "def suppress_stderr():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "# Setup\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2025.04.04.647211v1.full.pdf\"\n",
    "doi = \"10.1101/2025.04.04.647211\"\n",
    "file_path = \"paper4_fullscan.pdf\"\n",
    "\n",
    "# Download PDF\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Pattern: match ONLY integer triplets (no floats!)\n",
    "int_pattern = re.compile(r\"(?<![\\d.])(-?\\d{1,3})(?!\\.)\\s+(-?\\d{1,3})(?!\\.)\\s+(-?\\d{1,3})(?!\\.)\")\n",
    "\n",
    "# Extract paper 4\n",
    "results = []\n",
    "with suppress_stderr():\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            text = page.extract_text()\n",
    "            if not text:\n",
    "                continue\n",
    "            lines = text.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                matches = list(int_pattern.finditer(line))\n",
    "                if matches:\n",
    "                    x, y, z = map(int, matches[-1].groups())  # Get the last match on the line\n",
    "                    if all(-100 < val < 100 for val in (x, y, z)):\n",
    "                        results.append({\n",
    "                            \"DOI\": doi,\n",
    "                            \"Page\": i,\n",
    "                            \"x\": x,\n",
    "                            \"y\": y,\n",
    "                            \"z\": z\n",
    "                        })\n",
    "\n",
    "# Output\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No MNI coordinates found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b253ca-45b7-47e9-8bf8-d8280ee25005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNI coordinates found:\n",
      "                          DOI  Page   x   y   z\n",
      "0   10.1101/2025.03.24.645080    42 -10 -99   8\n",
      "1   10.1101/2025.03.24.645080    42   8 -83  -5\n",
      "2   10.1101/2025.03.24.645080    42 -13 -83 -10\n",
      "3   10.1101/2025.03.24.645080    42  12 -47 -70\n",
      "4   10.1101/2025.03.24.645080    42   4  47 -65\n",
      "5   10.1101/2025.03.24.645080    42 -55 -21  52\n",
      "6   10.1101/2025.03.24.645080    42 -44 -26  63\n",
      "7   10.1101/2025.03.24.645080    42 -42 -16  13\n",
      "8   10.1101/2025.03.24.645080    42  39  -8  11\n",
      "9   10.1101/2025.03.24.645080    42 -52 -70   8\n",
      "10  10.1101/2025.03.24.645080    42 -52 -42 -10\n"
     ]
    }
   ],
   "source": [
    "'''Paper 5: This is the paper where the code was initially also recognizing values from tables\n",
    "that did not include the coordinates just because it fit in the -100<n<100 values. \n",
    "So i included another criteria to look at the validity of all values in that table to figure out if those are actually coordinates or not.'''\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import requests\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_tables(file_path: str, page: str | int):\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
    "            return camelot.read_pdf(file_path, pages=str(page), flavor=\"stream\")\n",
    "\n",
    "def is_valid_mni_triplet(x, y, z):\n",
    "    return all(-100 < val < 100 for val in (x, y, z))\n",
    "\n",
    "def extract_valid_mni_table(table_df: pd.DataFrame, validity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Only return MNI coordinates if a sufficient percentage of rows contain valid triplets.\n",
    "    \"\"\"\n",
    "    mni_data = []\n",
    "    valid_rows = 0\n",
    "    candidate_rows = 0\n",
    "\n",
    "    for _, row in table_df.iterrows():\n",
    "        row = row.dropna().tolist()\n",
    "        numeric = []\n",
    "\n",
    "        for cell in row:\n",
    "            try:\n",
    "                numeric.append(int(cell))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if len(numeric) >= 3:\n",
    "            candidate_rows += 1\n",
    "            for i in range(len(numeric) - 2):\n",
    "                x, y, z = numeric[i], numeric[i+1], numeric[i+2]\n",
    "                if is_valid_mni_triplet(x, y, z):\n",
    "                    mni_data.append((x, y, z))\n",
    "                    valid_rows += 1\n",
    "                    break\n",
    "\n",
    "    if candidate_rows == 0:\n",
    "        return []  # Not a numeric table\n",
    "\n",
    "    if valid_rows / candidate_rows >= validity_threshold:\n",
    "        return mni_data  # Accept table as valid\n",
    "    else:\n",
    "        return []  # Reject noisy table\n",
    "\n",
    "# Paper-specific setup\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2025.03.24.645080v2.full.pdf\"\n",
    "doi = \"10.1101/2025.03.24.645080\"\n",
    "file_path = \"paper5.pdf\"\n",
    "\n",
    "# Download PDF paper 5\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Scan and validate tables\n",
    "results = []\n",
    "for page in range(1, 48):\n",
    "    try:\n",
    "        tables = read_tables(file_path, page)\n",
    "        for table in tables:\n",
    "            coords = extract_valid_mni_table(table.df, validity_threshold=0.8)\n",
    "            for x, y, z in coords:\n",
    "                results.append({\n",
    "                    \"DOI\": doi,\n",
    "                    \"Page\": page,\n",
    "                    \"x\": x,\n",
    "                    \"y\": y,\n",
    "                    \"z\": z\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Output\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    print(\"MNI coordinates found:\")\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No valid MNI coordinates found in this paper.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a5f82f-c763-4c02-a4e6-7c61f524c981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           DOI  Page   x   y   z\n",
      "0    10.1101/2025.02.19.639155    21 -50  10  22\n",
      "1    10.1101/2025.02.19.639155    21 -50  10  20\n",
      "2    10.1101/2025.02.19.639155    21 -48  18  -2\n",
      "3    10.1101/2025.02.19.639155    21 -50  16  -6\n",
      "4    10.1101/2025.02.19.639155    21 -48  12  14\n",
      "..                         ...   ...  ..  ..  ..\n",
      "119  10.1101/2025.02.19.639155    26  -8  14  -2\n",
      "120  10.1101/2025.02.19.639155    26  -8  -4   4\n",
      "121  10.1101/2025.02.19.639155    26  -4 -18   6\n",
      "122  10.1101/2025.02.19.639155    26 -14 -18  12\n",
      "123  10.1101/2025.02.19.639155    26 -58 -42  10\n",
      "\n",
      "[124 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Paper 6. This is the paper that required me to change the flavor from 'stream' to 'lattice'.\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import requests\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_tables(file_path: str, page: str | int):\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
    "            return camelot.read_pdf(file_path, pages=str(page), flavor=\"lattice\")\n",
    "\n",
    "def extract_mni_coordinates_from_table(table_df: pd.DataFrame):\n",
    "    mni_data = []\n",
    "    for _, row in table_df.iterrows():\n",
    "        row = row.dropna().tolist()\n",
    "        # Checking for 3 consecutive numeric values in row (neglecting the voxel count)\n",
    "        for i in range(len(row) - 2):\n",
    "            try:\n",
    "                x, y, z = int(row[i]), int(row[i+1]), int(row[i+2])\n",
    "                if all(-100 < val < 100 for val in (x, y, z)):\n",
    "                    mni_data.append((x, y, z))\n",
    "                    break  \n",
    "            except ValueError:\n",
    "                continue\n",
    "    return mni_data\n",
    "\n",
    "# Paper 6 Info\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2025.02.19.639155v1.full.pdf\"\n",
    "doi = \"10.1101/2025.02.19.639155\"\n",
    "file_path = \"paper6.pdf\"\n",
    "\n",
    "# Download PDF\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extracting MNI coordinates\n",
    "results = []\n",
    "for page in range(1, 27):\n",
    "    try:\n",
    "        tables = read_tables(file_path, page)\n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                coords = extract_mni_coordinates_from_table(table.df)\n",
    "                for x, y, z in coords:\n",
    "                    results.append({\n",
    "                        \"DOI\": doi,\n",
    "                        \"Page\": page,\n",
    "                        \"x\": x,\n",
    "                        \"y\": y,\n",
    "                        \"z\": z\n",
    "                    })\n",
    "    except Exception as e:\n",
    "        print(f\"Page {page} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# Output\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No MNI coordinates found in this paper.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8657e34a-346f-4b3c-86ac-f5fc230251ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         DOI  Page   x   y   z\n",
      "0  10.1101/2024.11.07.622453    24   3   4   5\n",
      "1  10.1101/2024.11.07.622453    30  10 -22  69\n",
      "2  10.1101/2024.11.07.622453    30  61 -36  26\n",
      "3  10.1101/2024.11.07.622453    30   4 -61  45\n",
      "4  10.1101/2024.11.07.622453    30  16 -56  19\n",
      "5  10.1101/2024.11.07.622453    30  27  12  56\n",
      "6  10.1101/2024.11.07.622453    30  45 -66  30\n"
     ]
    }
   ],
   "source": [
    "'''Paper 7 (i): Table extraction. \n",
    "This paper has mni coordinates in both, paragraph and table form. \n",
    "This code is just for the table. For this paper I experimented with the page range. \n",
    "I tried to write code that can parse through all pages of a paper, wihtout including its page range. \n",
    "All my older codes have a specific page range, so this code is useful if we simply want to feed the paper,\n",
    "and not change the range each time we do that.'''\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import requests\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import fitz  # to detect page count\n",
    "\n",
    "def read_tables(file_path: str, page: str | int):\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
    "            return camelot.read_pdf(file_path, pages=str(page), flavor=\"stream\")\n",
    "\n",
    "def extract_mni_coordinates_from_table(table_df: pd.DataFrame):\n",
    "    mni_data = []\n",
    "    for _, row in table_df.iterrows():\n",
    "        row = row.dropna().tolist()\n",
    "        for i in range(len(row) - 2):\n",
    "            try:\n",
    "                x, y, z = int(row[i]), int(row[i+1]), int(row[i+2])\n",
    "                if all(-100 < val < 100 for val in (x, y, z)):\n",
    "                    mni_data.append((x, y, z))\n",
    "                    break\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return mni_data\n",
    "\n",
    "# ---- Paper Info ---- #\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2024.11.07.622453v2.full.pdf\"\n",
    "doi = \"10.1101/2024.11.07.622453\"\n",
    "file_path = \"paper_generic.pdf\"\n",
    "\n",
    "# ---- Download PDF ---- #\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# ---- Automatically determine number of pages ---- #\n",
    "doc = fitz.open(file_path)\n",
    "total_pages = len(doc)\n",
    "doc.close()\n",
    "\n",
    "# ---- Extract MNI coordinates from all tables ---- #\n",
    "results = []\n",
    "for page in range(1, total_pages + 1):\n",
    "    try:\n",
    "        tables = read_tables(file_path, page)\n",
    "        for table in tables:\n",
    "            coords = extract_mni_coordinates_from_table(table.df)\n",
    "            for x, y, z in coords:\n",
    "                results.append({\n",
    "                    \"DOI\": doi,\n",
    "                    \"Page\": page,\n",
    "                    \"x\": x,\n",
    "                    \"y\": y,\n",
    "                    \"z\": z\n",
    "                })\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# ---- Output ---- #\n",
    "df1 = pd.DataFrame(results)\n",
    "if not df1.empty:\n",
    "    print(df1)\n",
    "else:\n",
    "    print(\"No correct MNI coordinates found in this paper.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fd210a-9eda-47a1-8196-4e2973cc244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         DOI  Page   x   y   z\n",
      "0  10.1101/2024.11.07.622453     1   1   3   4\n",
      "1  10.1101/2024.11.07.622453    12  38 -69  35\n",
      "2  10.1101/2024.11.07.622453    13  25 -11 -15\n",
      "3  10.1101/2024.11.07.622453    14  39 -24 -12\n",
      "4  10.1101/2024.11.07.622453    16  42 -70  40\n",
      "5  10.1101/2024.11.07.622453    16  39 -70  35\n"
     ]
    }
   ],
   "source": [
    "'''paper 7 (ii): paragraph coordinates extraction. \n",
    "In the coordinates in paragraph format, this paper had coordinates in no specific format like [x,y,z]. \n",
    "So i tried to write a code that could catch coordinates in different formats.'''\n",
    "# where coordinates can appear in paragraph text in formats like:\n",
    "# [x, y, z], (x, y, z), or just x, y, z\n",
    "#But it's still unable to find coordinates that are in the for of 'x, y and z'. This table does contain such wording, so I will have to tweak the code like that.\n",
    "#Since this is one of the first papers I have found that contains coordinates in both table, an paragraph format, I wasn't sure if i should merge the codes or not. \n",
    "#So for now, I have done them separately.\n",
    "#As you said, we might have to send each paper through various codes so it might work like that.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "# Paper Info\n",
    "pdf_url = \"https://www.biorxiv.org/content/10.1101/2024.11.07.622453v2.full.pdf\"\n",
    "doi = \"10.1101/2024.11.07.622453\"\n",
    "file_path = \"paper7.pdf\"\n",
    "\n",
    "# Download the PDF\n",
    "response = requests.get(pdf_url)\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Regex to match coordinates in any of these forms:\n",
    "# [x, y, z], (x, y, z), or x, y, z\n",
    "mni_pattern = re.compile(\n",
    "    r'[\\[\\(]?\\s*(-?\\d{1,3})\\s*,\\s*(-?\\d{1,3})\\s*,\\s*(-?\\d{1,3})\\s*[\\]\\)]?'\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "doc = fitz.open(file_path)\n",
    "for page_num in range(len(doc)):\n",
    "    text = doc[page_num].get_text()\n",
    "    matches = mni_pattern.findall(text)\n",
    "    \n",
    "    for match in matches:\n",
    "        x, y, z = map(int, match)\n",
    "        if all(-100 <= val <= 100 for val in (x, y, z)):\n",
    "            results.append({\n",
    "                \"DOI\": doi,\n",
    "                \"Page\": page_num + 1,\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"z\": z\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No valid MNI coordinates found in the paper.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
