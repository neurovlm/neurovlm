{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4863507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurovlm.data import get_data_dir\n",
    "from neurovlm.train import Trainer, which_device\n",
    "from neurovlm.models import TextAligner\n",
    "from neurovlm.loss import TruncatedLoss\n",
    "\n",
    "device = which_device()\n",
    "data_dir = get_data_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2c129",
   "metadata": {},
   "source": [
    "# Projection Head\n",
    "\n",
    "Projection head refers to a small network to align the latent spaces between text and neuroimages. The training regime starts with MSELoss, then gradually removed the influences of outliers through truncation, i.e. masking out the top-k% of loss instances from gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b3d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoded neurovecotrs from the second notebook\n",
    "latent_neuro, pmids_latent = torch.load(data_dir / \"latent_neuro_sparse.pt\", weights_only=False).values()\n",
    "\n",
    "# Load encoded text from last notebook\n",
    "latent_text_specter, pmids = torch.load(data_dir / \"latent_specter2_neuro.pt\", weights_only=False).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f32e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse\n",
    "mask =  pd.Series(pmids).isin(pmids_latent)\n",
    "pmids = pmids[mask]\n",
    "latent_text_specter = latent_text_specter[mask]\n",
    "assert (pmids == pmids_latent).all()\n",
    "\n",
    "mask = latent_neuro.norm(dim=1).detach().cpu().numpy() < 35 # sparser targets\n",
    "latent_neuro = latent_neuro[mask]\n",
    "latent_text_specter = latent_text_specter[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dict(\n",
    "    latent=latent_neuro,\n",
    "    pmid=pmids[mask],\n",
    "), data_dir/\"latent_neuro_sparse.pt\")\n",
    "\n",
    "torch.save(dict(\n",
    "    latent=latent_text_specter,\n",
    "    pmid=pmids[mask],\n",
    "), data_dir/\"latent_text_sparse.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c0023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test/validation split\n",
    "inds = torch.arange(len(latent_neuro))\n",
    "train_inds, test_inds = train_test_split(\n",
    "    inds, train_size=0.8, random_state=0\n",
    ")\n",
    "test_inds, val_inds = train_test_split(\n",
    "    test_inds, train_size=0.5, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e197babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: -1, val loss: 1.3713\n",
      "Epoch: 0, val loss: 1.327\n",
      "Epoch: 1, val loss: 1.2002\n",
      "Epoch: 2, val loss: 1.0351\n",
      "Epoch: 3, val loss: 0.9255\n",
      "Epoch: 4, val loss: 0.87431\n",
      "Epoch: 5, val loss: 0.85056\n",
      "Epoch: 6, val loss: 0.83867\n",
      "Epoch: 7, val loss: 0.83192\n",
      "Epoch: 8, val loss: 0.82779\n",
      "Epoch: 9, val loss: 0.82482\n",
      "Epoch: 10, val loss: 0.82236\n",
      "Epoch: 11, val loss: 0.8203\n",
      "Epoch: 12, val loss: 0.81827\n",
      "Epoch: 13, val loss: 0.81635\n",
      "Epoch: 14, val loss: 0.81424\n",
      "Epoch: 15, val loss: 0.81213\n",
      "Epoch: 16, val loss: 0.81013\n",
      "Epoch: 17, val loss: 0.80819\n",
      "Epoch: 18, val loss: 0.80624\n",
      "Epoch: 19, val loss: 0.80455\n",
      "Epoch: 20, val loss: 0.80307\n",
      "Epoch: 21, val loss: 0.80151\n",
      "Epoch: 22, val loss: 0.80001\n",
      "Epoch: 23, val loss: 0.79875\n",
      "Epoch: 24, val loss: 0.79755\n",
      "Epoch: 25, val loss: 0.79651\n",
      "Epoch: 26, val loss: 0.79524\n",
      "Epoch: 27, val loss: 0.79427\n",
      "Epoch: 28, val loss: 0.79337\n",
      "Epoch: 29, val loss: 0.7924\n",
      "Epoch: 30, val loss: 0.79175\n",
      "Epoch: 31, val loss: 0.79079\n",
      "Epoch: 32, val loss: 0.78987\n",
      "Epoch: 33, val loss: 0.7893\n",
      "Epoch: 34, val loss: 0.78842\n",
      "Epoch: 35, val loss: 0.78771\n",
      "Epoch: 36, val loss: 0.78706\n",
      "Epoch: 37, val loss: 0.78652\n",
      "Epoch: 38, val loss: 0.78589\n",
      "Epoch: 39, val loss: 0.78532\n",
      "Epoch: 40, val loss: 0.78474\n",
      "Epoch: 41, val loss: 0.78434\n",
      "Epoch: 42, val loss: 0.78388\n",
      "Epoch: 43, val loss: 0.78322\n",
      "Epoch: 44, val loss: 0.78279\n",
      "Epoch: 45, val loss: 0.78241\n",
      "Epoch: 46, val loss: 0.78198\n",
      "Epoch: 47, val loss: 0.78145\n",
      "Epoch: 48, val loss: 0.78106\n",
      "Epoch: 49, val loss: 0.7808\n",
      "Epoch: 50, val loss: 0.78039\n",
      "Epoch: 51, val loss: 0.78002\n",
      "Epoch: 52, val loss: 0.77983\n",
      "Epoch: 53, val loss: 0.77924\n",
      "Epoch: 54, val loss: 0.77903\n",
      "Epoch: 55, val loss: 0.77869\n",
      "Epoch: 56, val loss: 0.7783\n",
      "Epoch: 57, val loss: 0.77797\n",
      "Epoch: 58, val loss: 0.77787\n",
      "Epoch: 59, val loss: 0.77749\n",
      "Epoch: 60, val loss: 0.77724\n",
      "Epoch: 61, val loss: 0.77692\n",
      "Epoch: 62, val loss: 0.77683\n",
      "Epoch: 63, val loss: 0.77647\n",
      "Epoch: 64, val loss: 0.77629\n",
      "Epoch: 65, val loss: 0.77593\n",
      "Epoch: 66, val loss: 0.77581\n",
      "Epoch: 67, val loss: 0.77553\n",
      "Epoch: 68, val loss: 0.7753\n",
      "Epoch: 69, val loss: 0.7752\n",
      "Epoch: 70, val loss: 0.77502\n",
      "Epoch: 71, val loss: 0.77478\n",
      "Epoch: 72, val loss: 0.77477\n",
      "Epoch: 73, val loss: 0.77486\n",
      "Epoch: 74, val loss: 0.77462\n",
      "Epoch: 75, val loss: 0.77413\n",
      "Epoch: 76, val loss: 0.774\n",
      "Epoch: 77, val loss: 0.77381\n",
      "Epoch: 78, val loss: 0.7738\n",
      "Epoch: 79, val loss: 0.77361\n",
      "Epoch: 80, val loss: 0.77344\n",
      "Epoch: 81, val loss: 0.77317\n",
      "Epoch: 82, val loss: 0.77316\n",
      "Epoch: 83, val loss: 0.77293\n",
      "Epoch: 84, val loss: 0.77286\n",
      "Epoch: 85, val loss: 0.77263\n",
      "Epoch: 86, val loss: 0.77255\n",
      "Epoch: 87, val loss: 0.77247\n",
      "Epoch: 88, val loss: 0.77235\n",
      "Epoch: 89, val loss: 0.77229\n",
      "Epoch: 90, val loss: 0.77199\n",
      "Epoch: 91, val loss: 0.77187\n",
      "Epoch: 92, val loss: 0.77197\n",
      "Epoch: 93, val loss: 0.77161\n",
      "Epoch: 94, val loss: 0.77157\n",
      "Epoch: 95, val loss: 0.77146\n",
      "Epoch: 96, val loss: 0.77138\n",
      "Epoch: 97, val loss: 0.77119\n",
      "Epoch: 98, val loss: 0.77116\n",
      "Epoch: 99, val loss: 0.77113\n",
      "Epoch: 100, val loss: 0.77101\n",
      "Epoch: 101, val loss: 0.77087\n",
      "Epoch: 102, val loss: 0.77081\n",
      "Epoch: 103, val loss: 0.77064\n",
      "Epoch: 104, val loss: 0.77057\n",
      "Epoch: 105, val loss: 0.77046\n",
      "Epoch: 106, val loss: 0.77036\n",
      "Epoch: 107, val loss: 0.77011\n",
      "Epoch: 108, val loss: 0.77012\n",
      "Epoch: 109, val loss: 0.76999\n",
      "Epoch: 110, val loss: 0.76991\n",
      "Epoch: 111, val loss: 0.76985\n",
      "Epoch: 112, val loss: 0.76974\n",
      "Epoch: 113, val loss: 0.76976\n",
      "Epoch: 114, val loss: 0.76961\n",
      "Epoch: 115, val loss: 0.76945\n",
      "Epoch: 116, val loss: 0.76937\n",
      "Epoch: 117, val loss: 0.76931\n",
      "Epoch: 118, val loss: 0.76927\n",
      "Epoch: 119, val loss: 0.7691\n",
      "Epoch: 120, val loss: 0.76911\n",
      "Epoch: 121, val loss: 0.76898\n",
      "Epoch: 122, val loss: 0.76889\n",
      "Epoch: 123, val loss: 0.76883\n",
      "Epoch: 124, val loss: 0.76886\n",
      "Epoch: 125, val loss: 0.7686\n",
      "Epoch: 126, val loss: 0.76864\n",
      "Epoch: 127, val loss: 0.76878\n",
      "Epoch: 128, val loss: 0.76839\n",
      "Epoch: 129, val loss: 0.76862\n",
      "Epoch: 130, val loss: 0.76827\n",
      "Epoch: 131, val loss: 0.7684\n",
      "Epoch: 132, val loss: 0.7681\n",
      "Epoch: 133, val loss: 0.76811\n",
      "Epoch: 134, val loss: 0.76802\n",
      "Epoch: 135, val loss: 0.76792\n",
      "Epoch: 136, val loss: 0.76788\n",
      "Epoch: 137, val loss: 0.76777\n",
      "Epoch: 138, val loss: 0.76812\n",
      "Epoch: 139, val loss: 0.76766\n",
      "Epoch: 140, val loss: 0.76757\n",
      "Epoch: 141, val loss: 0.76748\n",
      "Epoch: 142, val loss: 0.76734\n",
      "Epoch: 143, val loss: 0.76737\n",
      "Epoch: 144, val loss: 0.76729\n",
      "Epoch: 145, val loss: 0.76726\n",
      "Epoch: 146, val loss: 0.76714\n",
      "Epoch: 147, val loss: 0.76704\n",
      "Epoch: 148, val loss: 0.76703\n",
      "Epoch: 149, val loss: 0.767\n",
      "Epoch: 150, val loss: 0.76686\n",
      "Epoch: 151, val loss: 0.76698\n",
      "Epoch: 152, val loss: 0.76683\n",
      "Epoch: 153, val loss: 0.76674\n",
      "Epoch: 154, val loss: 0.76661\n",
      "Epoch: 155, val loss: 0.7666\n",
      "Epoch: 156, val loss: 0.76655\n",
      "Epoch: 157, val loss: 0.76644\n",
      "Epoch: 158, val loss: 0.76647\n",
      "Epoch: 159, val loss: 0.76633\n",
      "Epoch: 160, val loss: 0.76632\n",
      "Epoch: 161, val loss: 0.76633\n",
      "Epoch: 162, val loss: 0.76622\n",
      "Epoch: 163, val loss: 0.76616\n",
      "Epoch: 164, val loss: 0.76623\n",
      "Epoch: 165, val loss: 0.76613\n",
      "Epoch: 166, val loss: 0.76598\n",
      "Epoch: 167, val loss: 0.76593\n",
      "Epoch: 168, val loss: 0.76586\n",
      "Epoch: 169, val loss: 0.76588\n",
      "Epoch: 170, val loss: 0.76591\n",
      "Epoch: 171, val loss: 0.76587\n",
      "Epoch: 172, val loss: 0.76571\n",
      "Epoch: 173, val loss: 0.76568\n",
      "Epoch: 174, val loss: 0.76575\n",
      "Epoch: 175, val loss: 0.76567\n",
      "Epoch: 176, val loss: 0.76565\n",
      "Epoch: 177, val loss: 0.76542\n",
      "Epoch: 178, val loss: 0.76542\n",
      "Epoch: 179, val loss: 0.76542\n",
      "Epoch: 180, val loss: 0.76533\n",
      "Epoch: 181, val loss: 0.7652\n",
      "Epoch: 182, val loss: 0.76522\n",
      "Epoch: 183, val loss: 0.76525\n",
      "Epoch: 184, val loss: 0.76522\n",
      "Epoch: 185, val loss: 0.76504\n",
      "Epoch: 186, val loss: 0.765\n",
      "Epoch: 187, val loss: 0.76504\n",
      "Epoch: 188, val loss: 0.76497\n",
      "Epoch: 189, val loss: 0.76497\n",
      "Epoch: 190, val loss: 0.76495\n",
      "Epoch: 191, val loss: 0.76485\n",
      "Epoch: 192, val loss: 0.76483\n",
      "Epoch: 193, val loss: 0.76471\n",
      "Epoch: 194, val loss: 0.7648\n",
      "Epoch: 195, val loss: 0.76464\n",
      "Epoch: 196, val loss: 0.76466\n",
      "Epoch: 197, val loss: 0.76462\n",
      "Epoch: 198, val loss: 0.76457\n",
      "Epoch: 199, val loss: 0.76461\n"
     ]
    }
   ],
   "source": [
    "proj_head = TextAligner(seed=123, latent_text_dim=768, hidden_dim=512, latent_neuro_dim=384)\n",
    "\n",
    "trainer_specter = Trainer(\n",
    "    proj_head,\n",
    "    batch_size=512,\n",
    "    n_epochs=200,\n",
    "    #lr=1e-4,\n",
    "    lr=5e-5,\n",
    "    #loss_fn=nn.L1Loss(),\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    X_val=latent_text_specter[val_inds],\n",
    "    y_val=latent_neuro[val_inds],\n",
    "    device=\"auto\"\n",
    ")\n",
    "\n",
    "trainer_specter.fit(\n",
    "    latent_text_specter[train_inds],\n",
    "    latent_neuro[train_inds]\n",
    ")\n",
    "\n",
    "proj_head = trainer_specter.model\n",
    "\n",
    "# Save\n",
    "trainer_specter.save(data_dir / f\"proj_head_mse_sparse.pt\")\n",
    "# Epoch: 199,  val loss:  1.1903 (initial) -> 0.71306 (current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c72984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn.plotting import plot_glass_brain\n",
    "from neurovlm.models import Specter\n",
    "\n",
    "# Load models\n",
    "proj_head = torch.load(data_dir / f\"proj_head_mse_sparse.pt\", weights_only=False)\n",
    "autoencoder = torch.load(data_dir / \"autoencoder_sparse.pt\", weights_only=False)\n",
    "decoder = autoencoder.decoder.to(\"cpu\")\n",
    "specter = Specter(\"allenai/specter2_aug2023refresh\", adapter=\"adhoc_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e11983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    # Regions\n",
    "    \"visual cortex\",\n",
    "    \"motor cortex\",\n",
    "    \"temporal lobe\",\n",
    "    \"cerebellum\",\n",
    "    \"precuneus\",\n",
    "    \"hippocampus\",\n",
    "    # Neurotransmitters\n",
    "    \"dopamine\",\n",
    "    \"serotonin\",\n",
    "    \"gaba\",\n",
    "    \"norepinephrine\",\n",
    "    # Networks\n",
    "    \"default mode network\",\n",
    "    \"salience network\",\n",
    "    \"executive control network\",\n",
    "    \"sensorimotor network\",\n",
    "    # Cognitiion\n",
    "    \"working memory\",\n",
    "    \"episodic memory\",\n",
    "    \"executive function\",\n",
    "    \"emotion regulation\",\n",
    "    \"attention\",\n",
    "    \"language processing\",\n",
    "    \"cognitive control\",\n",
    "    \"reward processing\",\n",
    "    # Conditions\n",
    "    \"major depressive disorder\",\n",
    "    \"schizophrenia\",\n",
    "    \"autism spectrum disorder\",\n",
    "    \"post-traumatic stress disorder (PTSD)\",\n",
    "    \"Alzheimer's disease\",\n",
    "    \"Parkinson's disease\",\n",
    "    \"ADHD\",\n",
    "    \"bipolar disorder\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mask\n",
    "mask_arrays = np.load(f\"{data_dir}/mask.npz\", allow_pickle=True)\n",
    "mask = mask_arrays[\"mask\"]\n",
    "affine = mask_arrays[\"affine\"]\n",
    "\n",
    "# Query\n",
    "decoder = autoencoder.decoder.to(\"cpu\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=15, ncols=2, figsize=(8, 25))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "\n",
    "    # Encode text\n",
    "    encoded_text_specter = specter(query)\n",
    "    encoded_text_specter = encoded_text_specter / encoded_text_specter.norm()\n",
    "\n",
    "    # Projection head\n",
    "    aligned_text_specter = proj_head.to(\"cpu\")(encoded_text_specter)\n",
    "\n",
    "    # Decode brain\n",
    "    neuro_pred = torch.sigmoid(decoder(aligned_text_specter)).detach().numpy()[0]\n",
    "\n",
    "    # Plot\n",
    "    pred = np.zeros(mask.shape)\n",
    "    pred[mask] = neuro_pred\n",
    "    img = nib.Nifti1Image(pred, affine)\n",
    "    plot_glass_brain(img, threshold=0, axes=axes[i])\n",
    "    axes[i].set_title(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
