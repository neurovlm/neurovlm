{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26337f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from keybert import KeyBERT\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from neurovlm.retrieval_resources import _load_dataframe, _load_specter, _load_latent_text\n",
    "from neurovlm.data import data_dir\n",
    "from neurovlm.train import Trainer, which_device\n",
    "\n",
    "# from neurovlm.models import ConceptClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2322c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(docs, ngram_range):\n",
    "    counts = CountVectorizer(\n",
    "        ngram_range=ngram_range,\n",
    "        stop_words=\"english\",\n",
    "        min_df=1\n",
    "    ).fit(docs)\n",
    "\n",
    "    X = counts.transform(docs)  # shape: (n_docs, n_features)\n",
    "\n",
    "    feature_names = counts.get_feature_names_out()\n",
    "\n",
    "    mask = np.array(X.sum(axis=0) >= 100)[0]\n",
    "\n",
    "    X = np.array(X[:, mask].todense())\n",
    "    feature_names = feature_names[mask]\n",
    "\n",
    "    return X, feature_names\n",
    "\n",
    "# Load text\n",
    "df = _load_dataframe()\n",
    "text = df[\"name\"] + \" [SEP] \" + df[\"description\"]\n",
    "\n",
    "# Extract n-grams\n",
    "if not (data_dir / \"ngram_matrix.npy\").exists():\n",
    "\n",
    "    X_uni, features_uni = extract_ngrams(text, (1, 1))\n",
    "    X_bi, features_bi = extract_ngrams(text, (2, 2))\n",
    "    X_tri, features_tri = extract_ngrams(text, (3, 3))\n",
    "\n",
    "    X = np.hstack((X_uni, X_bi, X_tri))\n",
    "    features = np.concat((features_uni, features_bi, features_tri))\n",
    "\n",
    "    np.save(data_dir / \"ngram_matrix.npy\", X)\n",
    "    np.save(data_dir / \"ngram_labels.npy\", features.astype(str))\n",
    "else:\n",
    "    X = np.load(data_dir / \"ngram_matrix.npy\")\n",
    "    features = np.load(data_dir / \"ngram_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31a4519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual cleaning\n",
    "DROP_SUBSTRINGS = [\n",
    "    # study-like language\n",
    "    \"study\", \"studies\", \"result\", \"indicate\", \"show\", \"related\",\n",
    "    \"differences\", \"significant\", \"effect\", \"role\", \"measure\",\n",
    "    \"displayed\", \"involved\", \"examined\", \"associated\", \"altered\",\n",
    "    \"performed\", \"demonstrated\", \"conclus\", \"correlate\", \"individuals\",\n",
    "    \"common\", \"prior\",\n",
    "    # too general\n",
    "    \"brain\", \"neural\", \"neuroimaging\", \"mri\", \"fmri\", \"connectivity\",\n",
    "    \"diagnosed\", \"patients\", \"little\", \"known\", \"activation\", \"blood\",\n",
    "    \"alterations\", \"neuroscience\", \"people\",\n",
    "]\n",
    "\n",
    "DROP_REGEXES = [\n",
    "    r\"^cortex\",\n",
    "    # general single terms\n",
    "    r\"^ventral$\", r\"^frontal$\", r\"^neuronal$\", r\"^cognitive$\",\n",
    "    r\"^cerebral$\", r\"^resting_state$\",  r\"^disorder$\",\n",
    "    r\"^neuropsychological$\", r\"^cognition$\", r\"^stimulus$\",\n",
    "    r\"^dysfunction$\", r\"^imaging$\", r\"^functional$\",\n",
    "    r\"^functional imaging$\", r\"^task performance$\", r\"^impairments$\",\n",
    "    r\"^traits$\", r\"^dysfunction$\",  r\"^cognitive abilities$\", r\"^imaging dti$\",\n",
    "    # [SEP] token\n",
    "    r\"\\bsep\\b\",\n",
    "]\n",
    "\n",
    "pattern = \"|\".join(\n",
    "    [re.escape(s) for s in DROP_SUBSTRINGS] +  # plain terms\n",
    "    DROP_REGEXES                               # regex terms\n",
    ")\n",
    "\n",
    "mask = ~pd.Series(features).str.contains(pattern, case=False, na=False, regex=True)\n",
    "features = features[mask]\n",
    "X = X[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec2261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "# specter embeddings for ngrams\n",
    "specter = _load_specter()\n",
    "specter.specter = specter.specter.eval()\n",
    "\n",
    "if not (data_dir / \"ngram_emb.pt\").exists():\n",
    "    ngram_emb = []\n",
    "    batch_size = 512\n",
    "    for i in tqdm(range(0, len(features), batch_size), total=ceil(len(features)//batch_size)):\n",
    "        with torch.no_grad():\n",
    "            ngram_emb.append(specter(features[i:i+batch_size].tolist()))\n",
    "    ngram_emb = torch.vstack(ngram_emb)\n",
    "\n",
    "    ngram_emb = ngram_emb / ngram_emb.norm(dim=1)[:, None] # unit vector\n",
    "    torch.save(ngram_emb, data_dir / \"ngram_emb.pt\")\n",
    "else:\n",
    "    ngram_emb = torch.load(data_dir / \"ngram_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e8fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latent text\n",
    "latent, pmids = _load_latent_text()\n",
    "\n",
    "# align df order, on pmid\n",
    "inds = df[\"pmid\"].argsort().values\n",
    "df = df.iloc[inds]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "X = X[inds]\n",
    "assert (df['pmid'] == pmids).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f031ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cosine similarity\n",
    "# sim = latent @ (ngram_emb / ngram_emb.norm(dim=1)[:, None]).T\n",
    "# sim[sim < 0.] = 0.\n",
    "# sim[X == 0] = 0.\n",
    "# y = sim.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f2de0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presence of n_grams is the prediction target\n",
    "y = X\n",
    "y = (y > 0).astype(float) # binary targets, rather than counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab2b403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure latent neuro vectors align with df\n",
    "latent_neuro, pmid = torch.load(\n",
    "    data_dir / \"latent_neuro_sparse.pt\", weights_only=False, map_location=\"cpu\"\n",
    ").values()\n",
    "\n",
    "assert (df[\"pmid\"] == df[\"pmid\"].sort_values()).all()\n",
    "\n",
    "mask = df['pmid'].isin(pmid)\n",
    "df, y = df[mask], y[mask]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# save\n",
    "np.save(data_dir  / \"y_ngram.npy\", y)\n",
    "np.save(data_dir / \"features_ngram.npy\", features)\n",
    "pd.Series(features).to_csv(\"tmp.csv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe037598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data splits\n",
    "train_ids, test_ids, val_ids = torch.load(data_dir / \"pmids_split.pt\", weights_only=False).values()\n",
    "train_ids.sort()\n",
    "val_ids.sort()\n",
    "test_ids.sort()\n",
    "\n",
    "def split(df, latent, y, pmids, device):\n",
    "    mask = df['pmid'].isin(pmids).to_numpy()\n",
    "    X = latent[torch.from_numpy(mask)].clone().to(device)\n",
    "    y = torch.from_numpy(y[mask].copy()).float().to(device)\n",
    "    pmids = pmids[pd.Series(pmids).isin(df[\"pmid\"])]\n",
    "    return X, y, pmids\n",
    "\n",
    "device = which_device()\n",
    "X_train, y_train, train_ids = split(df, latent_neuro, y, train_ids, device)\n",
    "X_val, y_val, val_ids = split(df, latent_neuro, y,  val_ids, device)\n",
    "X_test, y_test, test_ids = split(df, latent_neuro, y, test_ids, device)\n",
    "\n",
    "assert (df['pmid'] == df['pmid'].sort_values()).all()\n",
    "assert (train_ids == np.sort(train_ids)).all()\n",
    "assert (val_ids == np.sort(val_ids)).all()\n",
    "assert (test_ids == np.sort(test_ids)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5037d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neurovlm.retrieval_resources import _proj_head_image_infonce\n",
    "# proj_head = _proj_head_image_infonce()\n",
    "# proj_head = proj_head.to(device)\n",
    "# X_train = proj_head(X_train).detach()\n",
    "# X_test = proj_head(X_test).detach()\n",
    "# X_val = proj_head(X_val).detach()\n",
    "\n",
    "# norm = lambda x : x / x.norm(dim=1)[:, None]\n",
    "# X_train = norm(X_train)\n",
    "# X_test = norm(X_test)\n",
    "# X_val = norm(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d837b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptClf(nn.Module):\n",
    "    \"\"\"Predict concepts from latent neuro embeddings.\"\"\"\n",
    "    def __init__(self, d_out):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(384, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 1526),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1526, d_out)\n",
    "        )\n",
    "    def forward(self, X: torch.tensor):\n",
    "        return self.seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a4743f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: -1, val loss: 0.69408\n",
      "Epoch: 0, val loss: 0.60878\n",
      "Epoch: 10, val loss: 0.065173\n",
      "Epoch: 20, val loss: 0.064304\n",
      "Epoch: 30, val loss: 0.06368\n",
      "Epoch: 40, val loss: 0.063078\n",
      "Epoch: 50, val loss: 0.062456\n",
      "Epoch: 60, val loss: 0.061853\n",
      "Epoch: 70, val loss: 0.061275\n",
      "Epoch: 80, val loss: 0.060775\n",
      "Epoch: 90, val loss: 0.060334\n",
      "Epoch: 100, val loss: 0.059996\n",
      "Epoch: 110, val loss: 0.059714\n",
      "Epoch: 120, val loss: 0.059508\n",
      "Epoch: 130, val loss: 0.059316\n",
      "Epoch: 140, val loss: 0.0592\n",
      "Epoch: 150, val loss: 0.059047\n",
      "Epoch: 160, val loss: 0.058971\n",
      "Epoch: 170, val loss: 0.058892\n",
      "Epoch: 180, val loss: 0.05882\n",
      "Epoch: 190, val loss: 0.058751\n"
     ]
    }
   ],
   "source": [
    "clf = ConceptClf(X.shape[1]).to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    clf,\n",
    "    loss_fn,\n",
    "    lr=3e-5,\n",
    "    n_epochs=200,\n",
    "    batch_size=1028,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    interval=10\n",
    ")\n",
    "\n",
    "trainer.fit(X_train, y_train)\n",
    "\n",
    "# Epoch: -1, val loss: 0.69304\n",
    "# Epoch: 0, val loss: 0.63102\n",
    "# Epoch: 10, val loss: 0.060834\n",
    "# Epoch: 20, val loss: 0.060065\n",
    "# Epoch: 30, val loss: 0.059569\n",
    "# Epoch: 40, val loss: 0.059233\n",
    "# Epoch: 50, val loss: 0.059019\n",
    "# Epoch: 60, val loss: 0.058871\n",
    "# Epoch: 70, val loss: 0.05874\n",
    "# Epoch: 80, val loss: 0.05863\n",
    "# Epoch: 90, val loss: 0.058547\n",
    "# Epoch: 100, val loss: 0.058478\n",
    "# Epoch: 110, val loss: 0.058422\n",
    "# Epoch: 120, val loss: 0.058379\n",
    "# Epoch: 130, val loss: 0.058337\n",
    "# Epoch: 140, val loss: 0.0583"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274098a2",
   "metadata": {},
   "source": [
    "## PubMed Test Set\n",
    "todo: add test set results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val_pred = trainer.model(X_val) # <- change to test set, not val\n",
    "\n",
    "# # ii = 1 # 6\n",
    "# # print(df[df['pmid'].isin(val_ids).to_numpy()].iloc[ii][\"name\"])\n",
    "# # print(df[df['pmid'].isin(val_ids).to_numpy()].iloc[ii][\"description\"])\n",
    "\n",
    "# # true\n",
    "# _df = pd.DataFrame({\n",
    "#     \"phrase\": features,\n",
    "#     \"score\": y_val[ii].to(\"cpu\").detach().numpy()\n",
    "# })\n",
    "\n",
    "# _df.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "# # predicted\n",
    "# _df = pd.DataFrame({\n",
    "#     \"phrase\": features,\n",
    "#     \"score\": torch.sigmoid(y_val_pred[ii].to(\"cpu\").detach()).numpy()\n",
    "# })\n",
    "# _df.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d55d9d",
   "metadata": {},
   "source": [
    "## Network Correspondence Test Set\n",
    "\n",
    "Test generation on this on the DMN. This concept classifier identifies the correct terms. The LLM summarizes the terms into a wiki-like article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10142472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "from neurovlm.retrieval_resources import _load_masker, _load_autoencoder\n",
    "from nilearn.plotting import view_img\n",
    "\n",
    "masker = _load_masker()\n",
    "\n",
    "# Load network atlases\n",
    "with gzip.open(data_dir / \"networks.pkl.gz\", \"rb\") as f:\n",
    "    networks = pickle.load(f)\n",
    "networks = [(_k, k, v) for _k in networks.keys() for k, v in networks[_k].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d051816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rph/neurovlm/.env/lib/python3.12/site-packages/joblib/memory.py:326: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  return self.func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">NiftiMasker.wrapped</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Resampling images\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mNiftiMasker.wrapped\u001b[0m\u001b[1;34m]\u001b[0m Resampling images\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rph/neurovlm/.env/lib/python3.12/site-packages/joblib/memory.py:326: UserWarning: Resampling binary images with continuous or linear interpolation. This might lead to unexpected results. You might consider using nearest interpolation instead.\n",
      "  return self.func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "x = masker.transform(networks[14][2])\n",
    "\n",
    "autoencoder = _load_autoencoder()\n",
    "with torch.no_grad():\n",
    "    x = autoencoder.encoder(torch.from_numpy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3e77835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = proj_head.cpu()(x)\n",
    "# x = x/x.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b77e986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>posterior cingulate</td>\n",
       "      <td>0.744396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precuneus</td>\n",
       "      <td>0.662985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>default</td>\n",
       "      <td>0.650656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>posterior cingulate cortex</td>\n",
       "      <td>0.605690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default mode</td>\n",
       "      <td>0.600453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>default mode network</td>\n",
       "      <td>0.592126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mode network</td>\n",
       "      <td>0.581262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mode</td>\n",
       "      <td>0.579798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cingulate</td>\n",
       "      <td>0.573350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>regions</td>\n",
       "      <td>0.558416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>medial</td>\n",
       "      <td>0.538880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dmn</td>\n",
       "      <td>0.508576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>state</td>\n",
       "      <td>0.500959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>network</td>\n",
       "      <td>0.491735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>posterior</td>\n",
       "      <td>0.484242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resting</td>\n",
       "      <td>0.475890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resting state</td>\n",
       "      <td>0.454835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mode network dmn</td>\n",
       "      <td>0.435894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>healthy</td>\n",
       "      <td>0.428541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>network dmn</td>\n",
       "      <td>0.427761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      features    scores\n",
       "0          posterior cingulate  0.744396\n",
       "1                    precuneus  0.662985\n",
       "2                      default  0.650656\n",
       "3   posterior cingulate cortex  0.605690\n",
       "4                 default mode  0.600453\n",
       "5         default mode network  0.592126\n",
       "6                 mode network  0.581262\n",
       "7                         mode  0.579798\n",
       "8                    cingulate  0.573350\n",
       "9                      regions  0.558416\n",
       "10                      medial  0.538880\n",
       "11                         dmn  0.508576\n",
       "12                       state  0.500959\n",
       "13                     network  0.491735\n",
       "14                   posterior  0.484242\n",
       "15                     resting  0.475890\n",
       "16               resting state  0.454835\n",
       "17            mode network dmn  0.435894\n",
       "18                     healthy  0.428541\n",
       "19                 network dmn  0.427761"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.sigmoid(clf(x.to(device)).cpu().detach())\n",
    "\n",
    "_df = pd.DataFrame(dict(\n",
    "    features=features[scores.argsort().flip(0).numpy()],\n",
    "    scores=scores[scores.argsort().flip(0)]\n",
    "))\n",
    "\n",
    "_df.sort_values(\"scores\", ascending=False).iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "398ada80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = _df.rename(columns=dict(features=\"terms\", scores=\"weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab0c4ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Load LLM\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"left\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Eval mode and disable gradients\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "Write a wiki-style article related to the following set of terms. Ignore terms that are unrelated or unspecific. Find a common theme.\n",
    "\"\"\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77c2277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        terms   weights\n",
      "0         posterior cingulate  0.744396\n",
      "1                   precuneus  0.662985\n",
      "2                     default  0.650656\n",
      "3  posterior cingulate cortex  0.605690\n",
      "4                default mode  0.600453\n",
      "5        default mode network  0.592126\n",
      "6                mode network  0.581262\n",
      "7                        mode  0.579798\n",
      "8                   cingulate  0.573350\n",
      "9                     regions  0.558416\n"
     ]
    }
   ],
   "source": [
    "user_prompt = _df.sort_values(\"weights\", ascending=False).iloc[:10].to_string()\n",
    "\n",
    "# user_prompt = \"\\n\".join((user_prompt[\"terms\"] + \", \" +  user_prompt[\"weights\"].astype(str)).values)\n",
    "# user_prompt = \"terms, weights\\n\" + user_prompt\n",
    "# user_prompt\n",
    "\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19041dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\\n\".join(_df.sort_values(\"weights\", ascending=False).iloc[:10][\"terms\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "baa6977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt.strip(\"\\n\")},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=1000,\n",
    "        do_sample=True,\n",
    "        temperature=0.2,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=True,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "out = outputs[0][\"generated_text\"][-1][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa3e6087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Default Mode Network**\\n\\nThe Default Mode Network (DMN) is a set of brain regions that are active when an individual is not focused on the external environment and the brain is at \"wakeful rest.\" This network is characterized by its high activity during tasks such as daydreaming, mind-wandering, and recalling past events.\\n\\n**Key Regions of the Default Mode Network**\\n\\n1. **Posterior Cingulate Cortex**: The posterior cingulate cortex (PCC) is a region in the brain that plays a crucial role in the DMN. It is involved in error detection, conflict monitoring, and attentional control.\\n2. **Precuneus**: The precuneus is a region located in the parietal lobe that is also part of the DMN. It is involved in self-referential processing, memory retrieval, and spatial awareness.\\n3. **Medial Prefrontal Cortex**: Although not explicitly mentioned in the given terms, the medial prefrontal cortex (mPFC) is another key region of the DMN. It is involved in self-referential thinking, emotion regulation, and decision-making.\\n\\n**Functions of the Default Mode Network**\\n\\nThe DMN is thought to be involved in various cognitive processes, including:\\n\\n* **Self-referential thinking**: The ability to reflect on oneself, one\\'s thoughts, and emotions.\\n* **Memory retrieval**: The process of recalling past events and experiences.\\n* **Mind-wandering**: The tendency for the mind to wander away from the present moment and engage in daydreaming or fantasy.\\n* **Theory of mind**: The ability to attribute mental states to oneself and others.\\n\\n**Abnormalities in the Default Mode Network**\\n\\nDysfunction in the DMN has been implicated in various neurological and psychiatric disorders, including:\\n\\n* **Alzheimer\\'s disease**: Abnormalities in the PCC have been linked to early stages of Alzheimer\\'s disease.\\n* **Depression**: Altered activity in the mPFC and PCC has been observed in individuals with depression.\\n* **Schizophrenia**: Abnormalities in the DMN have been linked to symptoms of schizophrenia, such as hallucinations and delusions.\\n\\nIn conclusion, the default mode network is a complex system of brain regions that play a critical role in various cognitive processes, including self-referential thinking, memory retrieval, and mind-wandering. Dysfunction in this network has been implicated in various neurological and psychiatric disorders.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f93202",
   "metadata": {},
   "source": [
    "'**Default Mode Network**\n",
    "\n",
    "The Default Mode Network (DMN) is a set of brain regions that are active when an individual is not focused on the external environment and the brain is at \"wakeful rest.\" This network is characterized by its high activity during tasks such as daydreaming, mind-wandering, and recalling past events.\n",
    "\n",
    "**Key Regions of the Default Mode Network**\n",
    "\n",
    "1. **Posterior Cingulate Cortex**: The posterior cingulate cortex (PCC) is a region in the brain that plays a crucial role in the DMN. It is involved in error detection, conflict monitoring, and attentional control.\n",
    "2. **Precuneus**: The precuneus is a region located in the parietal lobe that is also part of the DMN. It is involved in self-referential processing, memory retrieval, and spatial awareness.\n",
    "3. **Medial Prefrontal Cortex**: Although not explicitly mentioned in the given terms, the medial prefrontal cortex (mPFC) is another key region of the DMN. It is involved in self-referential thinking, emotion regulation, and decision-making.\n",
    "\n",
    "**Functions of the Default Mode Network**\n",
    "\n",
    "The DMN is thought to be involved in various cognitive processes, including:\n",
    "\n",
    "* **Self-referential thinking**: The ability to reflect on oneself, one\\'s thoughts, and emotions.\n",
    "* **Memory retrieval**: The process of recalling past events and experiences.\n",
    "* **Mind-wandering**: The tendency for the mind to wander away from the present moment and engage in daydreaming or fantasy.\n",
    "* **Theory of mind**: The ability to attribute mental states to oneself and others.\n",
    "\n",
    "**Abnormalities in the Default Mode Network**\n",
    "\n",
    "Dysfunction in the DMN has been implicated in various neurological and psychiatric disorders, including:\n",
    "\n",
    "* **Alzheimer\\'s disease**: Abnormalities in the PCC have been linked to early stages of Alzheimer\\'s disease.\n",
    "* **Depression**: Altered activity in the mPFC and PCC has been observed in individuals with depression.\n",
    "* **Schizophrenia**: Abnormalities in the DMN have been linked to symptoms of schizophrenia, such as hallucinations and delusions.\n",
    "\n",
    "In conclusion, the default mode network is a complex system of brain regions that play a critical role in various cognitive processes, including self-referential thinking, memory retrieval, and mind-wandering. Dysfunction in this network has been implicated in various neurological and psychiatric disorders.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
