{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26337f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from neurovlm.retrieval_resources import (\n",
    "    _load_dataframe, _load_latent_text\n",
    ")\n",
    "from neurovlm.data import data_dir\n",
    "from neurovlm.train import Trainer, which_device\n",
    "from neurovlm.models import ConceptClf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567237d",
   "metadata": {},
   "source": [
    "# Concept Classifier\n",
    "\n",
    "The concept classifier predicts which concepts are present given a latent neuro embeddings. The top-10 related concepts are passed to an LLM to summarize the brain map. Here, Llama-3.1-8B-Instruct is used to generated interpretations. Any language model may be used. Larger models or models trained one neuroscience literature may provided better brain map interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d36ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram embeddings, from 06_n_grams.ipyn\n",
    "ngram_emb = torch.load(data_dir / \"ngram_emb.pt\")\n",
    "\n",
    "# load text\n",
    "df = _load_dataframe()\n",
    "df.sort_values(by=\"pmid\", inplace=True)\n",
    "text = df[\"name\"] + \" [SEP] \" + df[\"description\"]\n",
    "\n",
    "# load pre-computed ngrams from 06_n_grams.ipynb\n",
    "X = np.load(data_dir / \"ngram_matrix.npy\")\n",
    "features = np.load(data_dir / \"ngram_labels.npy\")\n",
    "\n",
    "# load latent text\n",
    "latent, pmids = _load_latent_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f031ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity as target\n",
    "y = latent @ (ngram_emb / ngram_emb.norm(dim=1)[:, None]).T\n",
    "m = (y < 0.) | (torch.from_numpy(X) == 0.)\n",
    "y[m==1] = 0.\n",
    "\n",
    "# transform cosine similarity ~= probabilities\n",
    "t = 0.03\n",
    "tau = 0.08\n",
    "y = torch.sigmoid((y - t)/ tau)\n",
    "\n",
    "y[m] = 0.\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2b403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure latent neuro vectors align with df\n",
    "latent_neuro, pmid = torch.load(\n",
    "    data_dir / \"latent_neuro.pt\", weights_only=False, map_location=\"cpu\"\n",
    ").values()\n",
    "\n",
    "assert (df[\"pmid\"] == df[\"pmid\"].sort_values()).all()\n",
    "\n",
    "mask = df['pmid'].isin(pmid)\n",
    "df, y = df[mask], y[mask]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe037598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data splits\n",
    "train_ids, test_ids, val_ids = torch.load(data_dir / \"pmids_split.pt\", weights_only=False).values()\n",
    "train_ids.sort()\n",
    "val_ids.sort()\n",
    "test_ids.sort()\n",
    "\n",
    "def split(df, latent, y, pmids, device):\n",
    "    mask = df['pmid'].isin(pmids).to_numpy()\n",
    "    X = latent[torch.from_numpy(mask)].clone().to(device)\n",
    "    y = torch.from_numpy(y[mask].copy()).float().to(device)\n",
    "    pmids = pmids[pd.Series(pmids).isin(df[\"pmid\"])]\n",
    "    return X, y, pmids\n",
    "\n",
    "device = which_device()\n",
    "X_train, y_train, train_ids = split(df, latent_neuro, y, train_ids, device)\n",
    "X_val, y_val, val_ids = split(df, latent_neuro, y,  val_ids, device)\n",
    "X_test, y_test, test_ids = split(df, latent_neuro, y, test_ids, device)\n",
    "\n",
    "# ensure sorted\n",
    "assert (df['pmid'] == df['pmid'].sort_values()).all()\n",
    "assert (train_ids == np.sort(train_ids)).all()\n",
    "assert (val_ids == np.sort(val_ids)).all()\n",
    "assert (test_ids == np.sort(test_ids)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d837b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: -1, val loss: 0.69848\n",
      "Epoch: 0, val loss: 0.32329\n",
      "Epoch: 20, val loss: 0.057988\n",
      "Epoch: 40, val loss: 0.056324\n",
      "Epoch: 60, val loss: 0.055724\n",
      "Epoch: 80, val loss: 0.055495\n",
      "Epoch: 100, val loss: 0.055371\n",
      "Epoch: 120, val loss: 0.055313\n",
      "Epoch: 140, val loss: 0.055283\n",
      "Epoch: 160, val loss: 0.055293\n",
      "Epoch: 180, val loss: 0.055316\n"
     ]
    }
   ],
   "source": [
    "clf = ConceptClf(X.shape[1]).to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    clf,\n",
    "    loss_fn,\n",
    "    lr=5e-5,\n",
    "    n_epochs=200,\n",
    "    batch_size=1028,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    interval=20\n",
    ")\n",
    "\n",
    "trainer.fit(X_train, y_train)\n",
    "\n",
    "trainer.save(data_dir / \"concept_clf.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75671b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurovlm.retrieval_resources import _load_masker, _load_autoencoder\n",
    "import gzip, pickle\n",
    "import nibabel as nib\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "masker = _load_masker()\n",
    "autoencoder = _load_autoencoder()\n",
    "\n",
    "# Load network atlases\n",
    "with gzip.open(data_dir / \"networks_arrays.pkl.gz\", \"rb\") as f:\n",
    "    networks = pickle.load(f)\n",
    "\n",
    "img = nib.Nifti1Image(networks[\"Du\"]['DN-A'][\"array\"], affine=networks[\"Du\"]['DN-B'][\"affine\"])\n",
    "x = masker.transform(\n",
    "    resample_to_img(img, masker.mask_img, interpolation=\"nearest\", force_resample=True, copy_header=True)\n",
    ")\n",
    "x = autoencoder.encoder(torch.from_numpy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d15e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top predicted terms for DN-A map:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['default', 'default mode', 'mode network', 'mode network dmn',\n",
       "       'default mode network', 'network', 'mode', 'network dmn', 'dmn',\n",
       "       'posterior cingulate', 'posterior', 'posterior cingulate cortex',\n",
       "       'medial', 'regions', 'retrosplenial', 'resting', 'resting state',\n",
       "       'cingulate', 'retrosplenial cortex', 'activity'], dtype='<U40')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.sigmoid(clf(x.to(\"cuda\")).cpu().detach())\n",
    "print(\"top predicted terms for DN-A map:\")\n",
    "features[scores.argsort(descending=True)][:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
