{
 "cells": [
  {
   "cell_type": "code",
   "id": "6bba59bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:05:25.689943Z",
     "start_time": "2026-01-20T07:05:21.180055Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from neurovlm.text_input import search_papers_from_text, search_wiki_from_text, generate_llm_response_from_text, search_cogatlas_from_text\n",
    "from neurovlm.brain_input import (\n",
    "    search_papers_from_brain,\n",
    "    generate_llm_response_from_brain,\n",
    "    resample_networks_to_mask\n",
    ")\n",
    "\n",
    "from neurovlm.retrieval_resources import (\n",
    "    _load_autoencoder,\n",
    "    _load_networks,\n",
    "    _load_masker )"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ollama Setup\n",
    "\n",
    "** 1. Install Ollama **\n",
    "- ** using brew: **\n",
    "```sh\n",
    "brew install ollama\n",
    "```\n",
    "\n",
    "** 2. Start Ollama Service **\n",
    "```\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "** 3. Download the ollama app **\n",
    "\n",
    "** 4. Pull a Model(Our default model is qwen2.5:7b) **\n",
    "```\n",
    "ollama pull qwen2.5:7b-instruct  or ollama pull qwen2.5:3b-instruct\n",
    "```\n"
   ],
   "id": "26218edee7c80f85"
  },
  {
   "cell_type": "markdown",
   "id": "2d0b30c7",
   "metadata": {},
   "source": [
    "## Load data and models"
   ]
  },
  {
   "cell_type": "code",
   "id": "15f5edf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:05:37.762206Z",
     "start_time": "2026-01-20T07:05:36.247744Z"
    }
   },
   "source": [
    "# Load data and Specter\n",
    "autoencoder = _load_autoencoder()\n",
    "\n",
    "masker = _load_masker()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f2549c56",
   "metadata": {},
   "source": [
    "## Example query for text\n",
    "\n",
    "The titles, abstract, cognitive concepts, cognitive tasks, and cognitive disorders most related to the query will be passed to the language model.\n",
    "\n",
    "The function accepts a string input; no need to encode the input text before passing it in"
   ]
  },
  {
   "cell_type": "code",
   "id": "3329e5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:05:38.403189Z",
     "start_time": "2026-01-20T07:05:38.399273Z"
    }
   },
   "source": [
    "query = \"default mode network\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "7de5ac50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:05:39.112872Z",
     "start_time": "2026-01-20T07:05:39.107408Z"
    }
   },
   "source": [
    "query"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default mode network'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "76f2e98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:06:36.216931Z",
     "start_time": "2026-01-20T07:05:40.108669Z"
    }
   },
   "source": [
    "# Get the top k similar papers\n",
    "abstract, titles = search_papers_from_text(query, show_titles = True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:629\u001B[39m, in \u001B[36mxet_get\u001B[39m\u001B[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001B[39m\n\u001B[32m    627\u001B[39m     progress.update(progress_bytes)\n\u001B[32m--> \u001B[39m\u001B[32m629\u001B[39m \u001B[43mdownload_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    630\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxet_download_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    631\u001B[39m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    632\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_info\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43maccess_token\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexpiration_unix_epoch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    633\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_refresher\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken_refresher\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    634\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprogress_updater\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mprogress_updater\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    635\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: Xet Runtime Error: Task cancelled; possible runtime shutdown in progress (task 9 was cancelled).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Get the top k similar papers\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m abstract, titles = \u001B[43msearch_papers_from_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_titles\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/src/neurovlm/text_input.py:48\u001B[39m, in \u001B[36msearch_papers_from_text\u001B[39m\u001B[34m(query, top_k, show_titles)\u001B[39m\n\u001B[32m     45\u001B[39m df = _load_dataframe()\n\u001B[32m     46\u001B[39m latent_text, latent_pmids = _load_latent_text()\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m specter = \u001B[43m_load_specter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     49\u001B[39m proj_head = _proj_head_text_infonce()\n\u001B[32m     51\u001B[39m encoded_query = specter(query)[\u001B[32m0\u001B[39m].detach().to(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/src/neurovlm/retrieval_resources.py:154\u001B[39m, in \u001B[36m_load_specter\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;129m@lru_cache\u001B[39m(maxsize=\u001B[32m1\u001B[39m)\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_load_specter\u001B[39m() -> Specter:\n\u001B[32m    153\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Construct and cache a Specter encoder.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m154\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSpecter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/src/neurovlm/models.py:189\u001B[39m, in \u001B[36mSpecter.__init__\u001B[39m\u001B[34m(self, model, adapter, orthgonalize, pooling, device)\u001B[39m\n\u001B[32m    186\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    187\u001B[39m         adapter_id = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00madapter\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m     \u001B[38;5;28mself\u001B[39m.specter = \u001B[43mAutoAdapterModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmodel\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m_base\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    190\u001B[39m     \u001B[38;5;28mself\u001B[39m.specter.load_adapter(adapter_id, source=\u001B[33m\"\u001B[39m\u001B[33mhf\u001B[39m\u001B[33m\"\u001B[39m, load_as=\u001B[33m\"\u001B[39m\u001B[33mspecter2\u001B[39m\u001B[33m\"\u001B[39m, set_active=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    192\u001B[39m \u001B[38;5;28mself\u001B[39m.specter = \u001B[38;5;28mself\u001B[39m.specter.to(\u001B[38;5;28mself\u001B[39m.device).eval()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:571\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    569\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    570\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m571\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    572\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    573\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    574\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    575\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    576\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping.keys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    577\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/transformers/modeling_utils.py:279\u001B[39m, in \u001B[36mrestore_default_torch_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    277\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    281\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/transformers/modeling_utils.py:4260\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4250\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   4251\u001B[39m     gguf_file\n\u001B[32m   4252\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4253\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m ((\u001B[38;5;28misinstance\u001B[39m(device_map, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map.values()) \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map)\n\u001B[32m   4254\u001B[39m ):\n\u001B[32m   4255\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   4256\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4257\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mloaded from GGUF files.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m4260\u001B[39m checkpoint_files, sharded_metadata = \u001B[43m_get_resolved_checkpoint_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4261\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4262\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4263\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4264\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4265\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4266\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4267\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4268\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4269\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4270\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4271\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4272\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4273\u001B[39m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4274\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4275\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4276\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4278\u001B[39m is_sharded = sharded_metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4279\u001B[39m is_quantized = hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/transformers/modeling_utils.py:1026\u001B[39m, in \u001B[36m_get_resolved_checkpoint_files\u001B[39m\u001B[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001B[39m\n\u001B[32m   1023\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1024\u001B[39m         \u001B[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001B[39;00m\n\u001B[32m   1025\u001B[39m         filename = _add_variant(WEIGHTS_NAME, variant)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m         resolved_archive_file = \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1027\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcached_file_kwargs\u001B[49m\n\u001B[32m   1028\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1029\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m resolved_archive_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filename == _add_variant(WEIGHTS_NAME, variant):\n\u001B[32m   1030\u001B[39m     \u001B[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001B[39;00m\n\u001B[32m   1031\u001B[39m     resolved_archive_file = cached_file(\n\u001B[32m   1032\u001B[39m         pretrained_model_name_or_path,\n\u001B[32m   1033\u001B[39m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001B[32m   1034\u001B[39m         **cached_file_kwargs,\n\u001B[32m   1035\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/transformers/utils/hub.py:266\u001B[39m, in \u001B[36mcached_file\u001B[39m\u001B[34m(path_or_repo_id, filename, **kwargs)\u001B[39m\n\u001B[32m    208\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcached_file\u001B[39m(\n\u001B[32m    209\u001B[39m     path_or_repo_id: Union[\u001B[38;5;28mstr\u001B[39m, os.PathLike],\n\u001B[32m    210\u001B[39m     filename: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m    211\u001B[39m     **kwargs,\n\u001B[32m    212\u001B[39m ) -> Optional[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m    213\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    214\u001B[39m \u001B[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001B[39;00m\n\u001B[32m    215\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    264\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m    265\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m266\u001B[39m     file = \u001B[43mcached_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    267\u001B[39m     file = file[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m file\n\u001B[32m    268\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/transformers/utils/hub.py:424\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    421\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    422\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(full_filenames) == \u001B[32m1\u001B[39m:\n\u001B[32m    423\u001B[39m         \u001B[38;5;66;03m# This is slightly better for only 1 file\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m424\u001B[39m         \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    425\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    426\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    427\u001B[39m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    428\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    429\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    430\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    431\u001B[39m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    432\u001B[39m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    433\u001B[39m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    434\u001B[39m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    435\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    436\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    437\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    438\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    439\u001B[39m         snapshot_download(\n\u001B[32m    440\u001B[39m             path_or_repo_id,\n\u001B[32m    441\u001B[39m             allow_patterns=full_filenames,\n\u001B[32m   (...)\u001B[39m\u001B[32m    450\u001B[39m             local_files_only=local_files_only,\n\u001B[32m    451\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001B[39m, in \u001B[36mhf_hub_download\u001B[39m\u001B[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[39m\n\u001B[32m    990\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_local_dir(\n\u001B[32m    991\u001B[39m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[32m    992\u001B[39m         local_dir=local_dir,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1007\u001B[39m         local_files_only=local_files_only,\n\u001B[32m   1008\u001B[39m     )\n\u001B[32m   1009\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1010\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_hf_hub_download_to_cache_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1011\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Destination\u001B[39;49;00m\n\u001B[32m   1012\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1013\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# File info\u001B[39;49;00m\n\u001B[32m   1014\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1015\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1017\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1018\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# HTTP info\u001B[39;49;00m\n\u001B[32m   1019\u001B[39m \u001B[43m        \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1020\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1021\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhf_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1022\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1023\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1024\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Additional options\u001B[39;49;00m\n\u001B[32m   1025\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1027\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:1171\u001B[39m, in \u001B[36m_hf_hub_download_to_cache_dir\u001B[39m\u001B[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[39m\n\u001B[32m   1168\u001B[39m \u001B[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001B[39;00m\n\u001B[32m   1170\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m WeakFileLock(lock_path):\n\u001B[32m-> \u001B[39m\u001B[32m1171\u001B[39m     \u001B[43m_download_to_tmp_and_move\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1172\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.incomplete\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1173\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdestination_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1174\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1175\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1176\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1177\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1178\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1179\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1180\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1181\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1183\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(pointer_path):\n\u001B[32m   1184\u001B[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:1723\u001B[39m, in \u001B[36m_download_to_tmp_and_move\u001B[39m\u001B[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001B[39m\n\u001B[32m   1721\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_xet_available():\n\u001B[32m   1722\u001B[39m     logger.debug(\u001B[33m\"\u001B[39m\u001B[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1723\u001B[39m     \u001B[43mxet_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1724\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1725\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1726\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1727\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1728\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdisplayed_filename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1729\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1730\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1731\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m constants.HF_HUB_DISABLE_XET:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:624\u001B[39m, in \u001B[36mxet_get\u001B[39m\u001B[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001B[39m\n\u001B[32m    613\u001B[39m     displayed_filename = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdisplayed_filename[:\u001B[32m40\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m(â€¦)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    615\u001B[39m progress_cm = _get_progress_bar_context(\n\u001B[32m    616\u001B[39m     desc=displayed_filename,\n\u001B[32m    617\u001B[39m     log_level=logger.getEffectiveLevel(),\n\u001B[32m   (...)\u001B[39m\u001B[32m    621\u001B[39m     _tqdm_bar=_tqdm_bar,\n\u001B[32m    622\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m624\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m progress_cm \u001B[38;5;28;01mas\u001B[39;00m progress:\n\u001B[32m    626\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprogress_updater\u001B[39m(progress_bytes: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[32m    627\u001B[39m         progress.update(progress_bytes)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/lab_work/neurovlm/.conda/lib/python3.12/site-packages/tqdm/std.py:1138\u001B[39m, in \u001B[36mtqdm.__exit__\u001B[39m\u001B[34m(self, exc_type, exc_value, traceback)\u001B[39m\n\u001B[32m   1135\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m   1136\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1138\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type, exc_value, traceback):\n\u001B[32m   1139\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1140\u001B[39m         \u001B[38;5;28mself\u001B[39m.close()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "0377d8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T05:34:47.281265Z",
     "start_time": "2026-01-20T05:34:46.941052Z"
    }
   },
   "source": "context, titles = search_wiki_from_text(\"dementia\", show_titles = True)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "1. Idiopathic disease\n",
      "2. SLC10A2\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T05:34:48.502548Z",
     "start_time": "2026-01-20T05:34:48.433253Z"
    }
   },
   "cell_type": "code",
   "source": "definition, terms, _ = search_cogatlas_from_text(query, show_titles=True)",
   "id": "174b0397d5a5f187",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "1. declarative knowledge\n",
      "2. spreading activation\n",
      "3. inference\n",
      "4. active maintenance\n",
      "5. intertemporal choice\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T05:34:51.138696Z",
     "start_time": "2026-01-20T05:34:50.636973Z"
    }
   },
   "cell_type": "code",
   "source": "definition, terms, _ = search_cogatlas_from_text(query, show_titles=True, category= \"cogatlas_disorder\")",
   "id": "6174b117efd5c0a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "1. mild cognitive impairment\n",
      "2. impotence\n",
      "3. melancholia\n",
      "4. anosognosia\n",
      "5. pedophilia\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T05:35:00.088068Z",
     "start_time": "2026-01-20T05:34:59.705820Z"
    }
   },
   "cell_type": "code",
   "source": "definition, terms, _ = search_cogatlas_from_text(query, show_titles=True, category= \"cogatlas_task\")",
   "id": "a7924940f5595d32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "1. lateral facilitation\n",
      "2. autism spectrum quotient\n",
      "3. autobiographical memory task\n",
      "4. local computation\n",
      "5. theory of mind task\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "44087e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:04:55.708745Z",
     "start_time": "2026-01-20T07:04:32.718360Z"
    }
   },
   "source": "output = generate_llm_response_from_text(query)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LLM response for query: 'default mode network'\n",
      "- Using papers\n",
      "- Using CogAtlas terms\n",
      "LLM writing summary...\n",
      "Loading model Qwen/Qwen2.5-3B-Instruct from Hugging Face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "47ff6716",
   "metadata": {},
   "source": [
    "## Example query for Brain Input\n",
    "\n",
    "The titles and abstract most related to the brain will be passed to the LM.\n",
    "\n",
    "The functions expects an already encoded brain input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0127f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network atlases\n",
    "networks = _load_networks()"
   ]
  },
  {
   "cell_type": "code",
   "id": "9038320b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T05:21:58.091287Z",
     "start_time": "2026-01-20T05:21:58.042568Z"
    }
   },
   "source": "networks_resampled = resample_networks_to_mask(networks)",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resample_networks_to_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m networks_resampled = \u001B[43mresample_networks_to_mask\u001B[49m(networks)\n",
      "\u001B[31mNameError\u001B[39m: name 'resample_networks_to_mask' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf6c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288047065eb14856be8db8341d2277d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "networks_embed = {}\n",
    "\n",
    "for k, v in tqdm(networks_resampled.items(), total=len(networks_resampled)):\n",
    "    networks_embed[k] = autoencoder.encoder(torch.from_numpy(masker.transform(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fca2f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "1. Neural correlates of sound externalization.\n",
      "2. Audio-visual synchrony modulates the ventriloquist illusion and its neural/spatial representation in the auditory cortex.\n",
      "3. Processing of spectral and amplitude envelope of animal vocalizations in the human auditory cortex.\n",
      "4. Music listening engages specific cortical regions within the temporal lobes: Differences between musicians and non-musicians.\n",
      "5. Processing of natural sounds in human auditory cortex: tonotopy, spectral tuning, and relation to voice sensitivity.\n"
     ]
    }
   ],
   "source": [
    "# Look for abstract and titles related to Auditory network\n",
    "abstract, titles, _ = search_papers_from_brain(networks_embed[\"AUD\"], show_titles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401467fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM summary for related abstracts\n",
    "output = generate_llm_response_from_brain(networks_embed[\"AUD\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neurovlm)",
   "language": "python",
   "name": "neurovlm"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
