{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffb1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle, gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import maskers\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn.image import resample_img\n",
    "\n",
    "from neurovlm.data import data_dir\n",
    "from neurovlm.models import Specter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7ced54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "# Load network atlases\n",
    "with gzip.open(\"/Users/ryanhammonds/projects/cbig_network_correspondence/networks.pkl.gz\", \"rb\") as f:\n",
    "    networks = pickle.load(f)\n",
    "\n",
    "# Load models\n",
    "proj_head = torch.load(data_dir / f\"proj_head_mse_sparse_adhoc.pt\", weights_only=False).cpu()\n",
    "specter = Specter(\"allenai/specter2_aug2023refresh\", adapter=\"adhoc_query\")\n",
    "autoencoder = torch.load(data_dir / \"autoencoder_sparse.pt\", weights_only=False).cpu()\n",
    "\n",
    "mask_arrays = np.load(f\"{data_dir}/mask.npz\", allow_pickle=True)\n",
    "mask_img = nib.Nifti1Image(mask_arrays[\"mask\"].astype(float),  mask_arrays[\"affine\"])\n",
    "masker = maskers.NiftiMasker(mask_img=mask_img, dtype=np.float32).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1745c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa04b6ef84bd461f92ca9097757aba8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845cb91317cb4207a996c2a0812bd118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resamples networks\n",
    "networks = {k: v for _k in networks.keys() for k, v in networks[_k].items()}\n",
    "networks_resampled = {}\n",
    "\n",
    "for k, img in tqdm(networks.items(), total=len(networks)):\n",
    "    img_arr = img.get_fdata()\n",
    "\n",
    "    if len(np.unique(img_arr)) == 2:\n",
    "        # binary data\n",
    "        img_resampled = resample_img(img, mask_arrays[\"affine\"], interpolation=\"nearest\")\n",
    "    else:\n",
    "        img_resampled = resample_img(img, mask_arrays[\"affine\"])\n",
    "        img_resampled_arr = img_resampled.get_fdata()\n",
    "        img_resampled_arr[img_resampled_arr < 0] = 0.\n",
    "        thresh = np.percentile(img_resampled_arr.flatten(), 95)\n",
    "        img_resampled_arr[img_resampled_arr < thresh] = 0.\n",
    "        img_resampled_arr[img_resampled_arr >= thresh] = 1.\n",
    "        img_resampled = nib.Nifti1Image(img_resampled_arr, affine=mask_arrays[\"affine\"])\n",
    "\n",
    "    networks_resampled[k] = img_resampled\n",
    "\n",
    "# Encode networks\n",
    "networks_embed = {}\n",
    "for k, v in tqdm(networks_resampled.items(), total=len(networks_resampled)):\n",
    "    networks_embed[k] = autoencoder.encoder(torch.from_numpy(masker.transform(v)[0]))\n",
    "\n",
    "# Save\n",
    "with open(\"neworks_embed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(networks_embed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90391b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip above and load\n",
    "with open(\"neworks_embed.pkl\", \"rb\") as f:\n",
    "    networks_embed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ba943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive projection heads\n",
    "proj_head_text = torch.load(data_dir / \"proj_head_text_infonce.pt\", weights_only=False).to('cpu')\n",
    "proj_head_image = torch.load(data_dir / \"proj_head_image_infonce.pt\", weights_only=False).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf00fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label networks\n",
    "network_labels = [\n",
    "    'default mode network',\n",
    "    'frontoparietal network',\n",
    "    \"control network\",\n",
    "    'cognitive control network',\n",
    "    'dorsal attention network',\n",
    "    'salience network',\n",
    "    'somatosensory network',\n",
    "    'motor network',\n",
    "    'somatomotor network',\n",
    "    'visual network',\n",
    "    'language network',\n",
    "    'executive control network',\n",
    "    'auditory network',\n",
    "    'limbic emotional network',\n",
    "    'multiple demand network',\n",
    "    'subcortical network',\n",
    "    'cerebellar network'\n",
    "]\n",
    "\n",
    "label_embeddings = specter(network_labels)\n",
    "label_embeddings = label_embeddings / label_embeddings.norm(dim=1)[:, None]\n",
    "\n",
    "label_embeddings = proj_head_text(label_embeddings)\n",
    "label_embeddings = label_embeddings / label_embeddings.norm(dim=1)[:, None]\n",
    "\n",
    "primary_label = []\n",
    "secondary_label = []\n",
    "primary_label_sim_score = []\n",
    "secondary_label_sim_score = []\n",
    "atlas_label = []\n",
    "results = {}\n",
    "i = 0\n",
    "for k, img_embed in networks_embed.items():\n",
    "    img_embed = proj_head_image(img_embed)\n",
    "    img_embed = img_embed / img_embed.norm()\n",
    "    cossim = label_embeddings @ img_embed\n",
    "    inds = torch.argsort(cossim, descending=True)\n",
    "    primary_label.append(network_labels[inds[0]])\n",
    "    primary_label_sim_score.append(float(cossim[inds[0]]))\n",
    "    secondary_label.append(network_labels[inds[1]])\n",
    "    secondary_label_sim_score.append(float(cossim[inds[1]]))\n",
    "    atlas_label.append(k)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7590ff01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atlas_label</th>\n",
       "      <th>predicted_label_primary</th>\n",
       "      <th>predicted_label_secondary</th>\n",
       "      <th>primary_cossim_score</th>\n",
       "      <th>secondar_cossim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VIS-P</td>\n",
       "      <td>visual network</td>\n",
       "      <td>cerebellar network</td>\n",
       "      <td>0.221639</td>\n",
       "      <td>0.206852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG-OP</td>\n",
       "      <td>executive control network</td>\n",
       "      <td>somatosensory network</td>\n",
       "      <td>0.101840</td>\n",
       "      <td>0.091646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DN-B</td>\n",
       "      <td>default mode network</td>\n",
       "      <td>frontoparietal network</td>\n",
       "      <td>0.156981</td>\n",
       "      <td>0.155471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOT-B</td>\n",
       "      <td>somatosensory network</td>\n",
       "      <td>motor network</td>\n",
       "      <td>0.267073</td>\n",
       "      <td>0.236592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUD</td>\n",
       "      <td>auditory network</td>\n",
       "      <td>somatosensory network</td>\n",
       "      <td>0.186340</td>\n",
       "      <td>0.036143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PM-PPr</td>\n",
       "      <td>motor network</td>\n",
       "      <td>somatosensory network</td>\n",
       "      <td>0.285581</td>\n",
       "      <td>0.258426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dATN-B</td>\n",
       "      <td>visual network</td>\n",
       "      <td>dorsal attention network</td>\n",
       "      <td>0.355336</td>\n",
       "      <td>0.294363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOT-A</td>\n",
       "      <td>somatosensory network</td>\n",
       "      <td>motor network</td>\n",
       "      <td>0.332540</td>\n",
       "      <td>0.295238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LANG</td>\n",
       "      <td>language network</td>\n",
       "      <td>auditory network</td>\n",
       "      <td>0.095445</td>\n",
       "      <td>0.091745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FPN-B</td>\n",
       "      <td>frontoparietal network</td>\n",
       "      <td>default mode network</td>\n",
       "      <td>0.128733</td>\n",
       "      <td>0.114357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  atlas_label    predicted_label_primary predicted_label_secondary  \\\n",
       "0       VIS-P             visual network        cerebellar network   \n",
       "1       CG-OP  executive control network     somatosensory network   \n",
       "2        DN-B       default mode network    frontoparietal network   \n",
       "3      SMOT-B      somatosensory network             motor network   \n",
       "4         AUD           auditory network     somatosensory network   \n",
       "5      PM-PPr              motor network     somatosensory network   \n",
       "6      dATN-B             visual network  dorsal attention network   \n",
       "7      SMOT-A      somatosensory network             motor network   \n",
       "8        LANG           language network          auditory network   \n",
       "9       FPN-B     frontoparietal network      default mode network   \n",
       "\n",
       "   primary_cossim_score  secondar_cossim_score  \n",
       "0              0.221639               0.206852  \n",
       "1              0.101840               0.091646  \n",
       "2              0.156981               0.155471  \n",
       "3              0.267073               0.236592  \n",
       "4              0.186340               0.036143  \n",
       "5              0.285581               0.258426  \n",
       "6              0.355336               0.294363  \n",
       "7              0.332540               0.295238  \n",
       "8              0.095445               0.091745  \n",
       "9              0.128733               0.114357  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"atlas_label\": atlas_label,\n",
    "    \"predicted_label_primary\": primary_label,\n",
    "    \"predicted_label_secondary\": secondary_label,\n",
    "    \"primary_cossim_score\": primary_label_sim_score,\n",
    "    \"secondar_cossim_score\": secondary_label_sim_score,\n",
    "})\n",
    "\n",
    "df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d9fbcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"~/Desktop/sim_updated.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
