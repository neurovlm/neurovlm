{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26337f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "from tqdm.notebook import tqdm\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from nilearn.image import resample_to_img\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from neurovlm.retrieval_resources import (\n",
    "    _load_masker, _load_autoencoder, _load_networks\n",
    ")\n",
    "from neurovlm.data import data_dir\n",
    "from neurovlm.models import ConceptClf\n",
    "from neurovlm.train import which_device\n",
    "device = which_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567237d",
   "metadata": {},
   "source": [
    "# Interpreting Brain Maps\n",
    "\n",
    "## Corpus Extraction\n",
    "Extract n-grams for the training corpus. N-grams are weighted by cosine similarity to article embeddings, e.g. if n-gram is highly similar to the articles it gets a value near 1, otherwise it gets a value near 0.\n",
    "\n",
    "# Concept Classifier\n",
    "The concept classifier predicts which concepts are present given a latent neuro embeddings. The top-10 related concepts are passed to an LLM to summarize the brain map. Here, Llama-3.1-8B-Instruct is used to generated interpretations. Any language model may be used. Larger models or models trained one neuroscience literature may provided better brain map interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c627b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from 10_n_grams.ipynb\n",
    "concept_clf = torch.load(data_dir / \"concept_clf.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d55d9d",
   "metadata": {},
   "source": [
    "## Network Correspondence\n",
    "\n",
    "Test geneartion on the network dataset. Predicted concepts are passed to the LLM to summarizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe3c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "masker = _load_masker()\n",
    "autoencoder = _load_autoencoder()\n",
    "networks = _load_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c4ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load LLM\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"left\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Eval mode and disable gradients\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db8dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a neuroscience editor writing a short wiki-style article from a list of terms.\n",
    "\n",
    "INPUT: a list of neuroscience terms (networks, brain regions, cognitive functions, disorders).\n",
    "OUTPUT: ONE article that uses the terms to form a coherent theme.\n",
    "\n",
    "Rules:\n",
    "1) Title (required): 6–12 words. Make it specific and content-based.\n",
    "   - Use 1–2 of the most informative terms (prefer: network/circuit + region + cognition; add disorder only if strongly supported).\n",
    "   - DO NOT use generic titles like: \"Summary\", \"Overview\", \"Brain Network Analysis\", \"A Summary of Terms\".\n",
    "\n",
    "2) Lead paragraph (2–3 sentences):\n",
    "   - State the unifying theme directly (what the terms collectively describe).\n",
    "   - Name 3–5 “anchor” terms that drive the theme.\n",
    "   - Do NOT say “the provided list”, “top-ranked”, “these terms appear”, or anything about scoring/ranking.\n",
    "\n",
    "3) Body sections:\n",
    "   - Networks\n",
    "   - Key Regions\n",
    "   - Cognitive Functions\n",
    "   - Clinical Relevance\n",
    "\n",
    "4) Be concrete:\n",
    "   - Prefer specific mechanisms, pathways, and canonical associations over vague statements.\n",
    "   - If a term is too vague/ambiguous/unrelated, ignore it in the main text.\n",
    "\n",
    "No references. Do not mention this prompt.\n",
    "\"\"\".strip()\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6657d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "with gzip.open(data_dir / \"networks_arrays.pkl.gz\", \"rb\") as f:\n",
    "    networks = pickle.load(f)\n",
    "\n",
    "network_imgs = []\n",
    "for k in networks.keys():\n",
    "    for a in networks[k].keys():\n",
    "        network_imgs.append((k, a, nib.Nifti1Image(networks[k][a][\"array\"], affine=networks[k][a][\"affine\"])))\n",
    "\n",
    "networks = [i for i in network_imgs if i[0] not in [\"UKBICA\", \"HCPICA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2eac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (data_dir / \"networks_emb.pt\").exists():\n",
    "    # Encode networks\n",
    "    networks_emb = torch.zeros((len(networks), 384))\n",
    "    for i, row in tqdm(enumerate(networks), total=len(networks)):\n",
    "        \n",
    "        # Encode network image\n",
    "        with torch.no_grad():\n",
    "            x = masker.transform(\n",
    "                resample_to_img(row[2], masker.mask_img, interpolation=\"nearest\", force_resample=True, copy_header=True)\n",
    "            )\n",
    "            x = autoencoder.encoder(torch.from_numpy(x))\n",
    "            networks_emb[i] = x\n",
    "\n",
    "    torch.save(networks_emb, data_dir / \"networks_emb.pt\")\n",
    "else:\n",
    "    networks_emb = torch.load(data_dir / \"networks_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70870c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a8257483d347218f6ed53bd5b6eff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load from 06_n_grams.ipynb\n",
    "features = np.load(data_dir / \"ngram_labels.npy\")\n",
    "mask = np.load(data_dir / \"ngram_mask.npy\")\n",
    "features = features[mask]\n",
    "\n",
    "# Compute llm response\n",
    "messages = []\n",
    "\n",
    "for i, row in tqdm(enumerate(networks), total=len(networks)):\n",
    "    \n",
    "    # Concept classifier\n",
    "    scores = torch.sigmoid(concept_clf(networks_emb[i].to(device)).cpu().detach())\n",
    "\n",
    "    # Pass concepts to LLM\n",
    "    user_prompt = \", \".join(features[scores.argsort().flip(0).numpy()[:20]])\n",
    "\n",
    "    messages.append([\n",
    "        {\"role\": \"system\", \"content\": system_prompt.strip(\"\\n\")},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0313e969b80840b0be182b77f59a10a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_summaries = []\n",
    "\n",
    "batch_size = 5\n",
    "for i in tqdm(range(0, len(networks), batch_size), total=ceil(len(networks)/batch_size)):\n",
    "    with torch.inference_mode():\n",
    "        outputs = pipe(\n",
    "            messages[i:i+batch_size],\n",
    "            max_new_tokens=1000,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.1,\n",
    "            return_full_text=True,\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "    for idx in range(len(outputs)):\n",
    "        generated_summary = outputs[idx][0][\"generated_text\"][-1][\"content\"].strip()\n",
    "        row = networks[i:i+batch_size][idx]\n",
    "        with open(f\"generated_summaries_{row[0].lower().replace(\"/\", \"-\")}_{row[1].lower().replace(\"/\", \"-\")}.txt\", \"w\") as f:\n",
    "            f.write(generated_summary)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nilearn import datasets, maskers\n",
    "\n",
    "atlas0 = datasets.fetch_atlas_harvard_oxford(\"cort-maxprob-thr25-2mm\")\n",
    "    \n",
    "atlas1 = datasets.fetch_atlas_schaefer_2018(\n",
    "    n_rois=400, yeo_networks=7, resolution_mm=2\n",
    ")\n",
    "\n",
    "labels0 = []\n",
    "labels1 = []\n",
    "for row in tqdm(networks, total=len(networks)):\n",
    "    for atlas, labels in [(atlas0, labels0), (atlas1, labels1)]:\n",
    "        img = row[-1]\n",
    "        labels_img = atlas.maps\n",
    "        _labels = list(atlas.labels)\n",
    "        masker = maskers.NiftiLabelsMasker(labels_img=labels_img, standardize=False)\n",
    "        region_means = masker.fit_transform(img)\n",
    "        df = pd.DataFrame({\n",
    "            \"label\": _labels[1:],\n",
    "            \"mean_activation\": region_means,\n",
    "        })\n",
    "        df = df.iloc[1:].sort_values(\"mean_activation\", ascending=False)\n",
    "        top_k = 5\n",
    "        top_regions = df.head(top_k)\n",
    "        labels.append(top_regions[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f824796",
   "metadata": {},
   "source": [
    "## PubMed Test Set\n",
    "todo: add test set results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val_pred = trainer.model(X_val) # <- change to test set, not val\n",
    "\n",
    "# # ii = 1 # 6\n",
    "# # print(df[df['pmid'].isin(val_ids).to_numpy()].iloc[ii][\"name\"])\n",
    "# # print(df[df['pmid'].isin(val_ids).to_numpy()].iloc[ii][\"description\"])\n",
    "\n",
    "# # true\n",
    "# _df = pd.DataFrame({\n",
    "#     \"phrase\": features,\n",
    "#     \"score\": y_val[ii].to(\"cpu\").detach().numpy()\n",
    "# })\n",
    "\n",
    "# _df.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "# # predicted\n",
    "# _df = pd.DataFrame({\n",
    "#     \"phrase\": features,\n",
    "#     \"score\": torch.sigmoid(y_val_pred[ii].to(\"cpu\").detach()).numpy()\n",
    "# })\n",
    "# _df.sort_values(by=\"score\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
