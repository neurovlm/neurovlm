{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26337f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "from tqdm.notebook import tqdm\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from nilearn.image import resample_to_img\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from neurovlm.retrieval_resources import (\n",
    "    _load_masker, _load_autoencoder, _load_networks\n",
    ")\n",
    "from neurovlm.data import data_dir\n",
    "from neurovlm.models import ConceptClf\n",
    "from neurovlm.train import which_device\n",
    "device = which_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567237d",
   "metadata": {},
   "source": [
    "# Interpreting Brain Maps\n",
    "\n",
    "## Corpus Extraction\n",
    "Extract n-grams for the training corpus. N-grams are weighted by cosine similarity to article embeddings, e.g. if n-gram is highly similar to the articles it gets a value near 1, otherwise it gets a value near 0.\n",
    "\n",
    "# Concept Classifier\n",
    "The concept classifier predicts which concepts are present given a latent neuro embeddings. The top-10 related concepts are passed to an LLM to summarize the brain map. Here, Llama-3.1-8B-Instruct is used to generated interpretations. Any language model may be used. Larger models or models trained one neuroscience literature may provided better brain map interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c627b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from 10_n_grams.ipynb\n",
    "concept_clf = torch.load(data_dir / \"concept_clf.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e130eb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30826, 2835)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load(data_dir / \"ngram_matrix.npy\")\n",
    "features = np.load(data_dir / \"ngram_labels.npy\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d55d9d",
   "metadata": {},
   "source": [
    "## Network Correspondence\n",
    "\n",
    "Test geneartion on the network dataset. Predicted concepts are passed to the LLM to summarizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe3c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "masker = _load_masker()\n",
    "autoencoder = _load_autoencoder()\n",
    "networks = _load_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab0c4ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load LLM\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"left\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Eval mode and disable gradients\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db8dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a neuroscience editor writing a short wiki-style article from a list of terms.\n",
    "\n",
    "INPUT: a list of neuroscience terms (networks, brain regions, cognitive functions, disorders).\n",
    "OUTPUT: ONE article that uses the terms to form a coherent theme.\n",
    "\n",
    "Rules:\n",
    "1) Title (required): 6–12 words. Make it specific and content-based.\n",
    "   - Use 1–2 of the most informative terms (prefer: network/circuit + region + cognition; add disorder only if strongly supported).\n",
    "   - DO NOT use generic titles like: \"Summary\", \"Overview\", \"Brain Network Analysis\", \"A Summary of Terms\".\n",
    "\n",
    "2) Lead paragraph (2–3 sentences):\n",
    "   - State the unifying theme directly (what the terms collectively describe).\n",
    "   - Name 3–5 “anchor” terms that drive the theme.\n",
    "   - Do NOT say “the provided list”, “top-ranked”, “these terms appear”, or anything about scoring/ranking.\n",
    "\n",
    "3) Body sections:\n",
    "   - Networks\n",
    "   - Key Regions\n",
    "   - Cognitive Functions\n",
    "   - Clinical Relevance\n",
    "\n",
    "4) Be concrete:\n",
    "   - Prefer specific mechanisms, pathways, and canonical associations over vague statements.\n",
    "   - If a term is too vague/ambiguous/unrelated, ignore it in the main text.\n",
    "\n",
    "No references. Do not mention this prompt.\n",
    "\"\"\".strip()\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6657d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "with gzip.open(data_dir / \"networks_arrays.pkl.gz\", \"rb\") as f:\n",
    "    networks = pickle.load(f)\n",
    "\n",
    "network_imgs = []\n",
    "for k in networks.keys():\n",
    "    for a in networks[k].keys():\n",
    "        network_imgs.append((k, a, nib.Nifti1Image(networks[k][a][\"array\"], affine=networks[k][a][\"affine\"])))\n",
    "\n",
    "networks = [i for i in network_imgs if i[0] not in [\"UKBICA\", \"HCPICA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2eac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (data_dir / \"networks_emb.pt\").exists():\n",
    "    # Encode networks\n",
    "    networks_emb = torch.zeros((len(networks), 384))\n",
    "    for i, row in tqdm(enumerate(networks), total=len(networks)):\n",
    "\n",
    "        # Encode network image\n",
    "        with torch.no_grad():\n",
    "            x = masker.transform(\n",
    "                resample_to_img(row[2], masker.mask_img, interpolation=\"nearest\", force_resample=True, copy_header=True)\n",
    "            )\n",
    "            x = autoencoder.encoder(torch.from_numpy(x))\n",
    "            networks_emb[i] = x\n",
    "\n",
    "    torch.save(networks_emb, data_dir / \"networks_emb.pt\")\n",
    "else:\n",
    "    networks_emb = torch.load(data_dir / \"networks_emb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70870c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97dc8b9e6ab43c89a05be3b7819eb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load from 06_n_grams.ipynb\n",
    "features = np.load(data_dir / \"ngram_labels.npy\")\n",
    "\n",
    "# Compute llm response\n",
    "messages = []\n",
    "\n",
    "for i, row in tqdm(enumerate(networks), total=len(networks)):\n",
    "\n",
    "    # Concept classifier\n",
    "    scores = torch.sigmoid(concept_clf(networks_emb[i].to(device)).cpu().detach())\n",
    "\n",
    "    # Pass concepts to LLM\n",
    "    user_prompt = \", \".join(features[scores.argsort().flip(0).numpy()[:20]])\n",
    "\n",
    "    messages.append([\n",
    "        {\"role\": \"system\", \"content\": system_prompt.strip(\"\\n\")},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011b5342f7b741f0ab96d3cbc33e05cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "out_dir = data_dir / \"networks_text_gen\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "generated_summaries = []\n",
    "batch_size = 5\n",
    "for i in tqdm(range(0, len(networks), batch_size), total=ceil(len(networks)/batch_size)):\n",
    "    with torch.inference_mode():\n",
    "        outputs = pipe(\n",
    "            messages[i:i+batch_size],\n",
    "            max_new_tokens=1000,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.1,\n",
    "            return_full_text=True,\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "    for idx in range(len(outputs)):\n",
    "        generated_summary = outputs[idx][0][\"generated_text\"][-1][\"content\"].strip()\n",
    "        row = networks[i:i+batch_size][idx]\n",
    "        with open(out_dir / f\"generated_summaries_{row[0].lower().replace(\"/\", \"-\")}_{row[1].lower().replace(\"/\", \"-\")}.txt\", \"w\") as f:\n",
    "            f.write(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ceb46d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(out_dir.glob(\"*.txt\"))\n",
    "files.sort()\n",
    "rows = []\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        txt = f.read().strip()\n",
    "    atlas, name = str(file).split(\"generated_summaries_\")[-1].split(\".txt\")[0].split(\"_\")\n",
    "    rows.append((atlas, name, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a177af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    \"atlas\": [i[0] for i in rows],\n",
    "    \"name\": [i[1] for i in rows],\n",
    "    \"text\": [i[2] for i in rows]\n",
    "})\n",
    "\n",
    "df_results.to_csv(data_dir / \"networks_text_gen.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
