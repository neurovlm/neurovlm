{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18570728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from neurovlm.metrics import recall_curve\n",
    "from neurovlm.data import data_dir\n",
    "from neurovlm.retrieval_resources import (\n",
    "    _load_autoencoder, _load_masker, _proj_head_text_mse,\n",
    "    _proj_head_image_infonce, _proj_head_text_infonce,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5a738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models\n",
    "masker = _load_masker()\n",
    "autoencoder = _load_autoencoder()\n",
    "proj_head = _proj_head_text_mse()\n",
    "proj_head_text = _proj_head_text_infonce()\n",
    "proj_head_image = _proj_head_image_infonce()\n",
    "\n",
    "# Load neurovault\n",
    "neurovault_data = torch.load(\n",
    "    data_dir / \"neurovault.pt\", weights_only=False\n",
    ")\n",
    "df_neuro, df_pubs, _, neuro_clust, _, _, text_emb = neurovault_data.values()\n",
    "\n",
    "sim_mean = torch.zeros(len(df_pubs))\n",
    "sim_mean_dec = torch.zeros(len(df_pubs))\n",
    "\n",
    "latent_image = torch.zeros((len(df_pubs), 384))\n",
    "latent_text = torch.zeros((len(df_pubs), 384))\n",
    "\n",
    "latent_image_dec = torch.zeros((len(df_pubs), 384))\n",
    "latent_text_dec = torch.zeros((len(df_pubs), 384))\n",
    "\n",
    "for i, doi in enumerate(df_pubs[\"doi\"]):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Encoded image\n",
    "        im = autoencoder.encoder(torch.from_numpy(\n",
    "            neuro_clust[np.where(df_neuro[\"doi\"] == doi)[0]] > 0\n",
    "        ).to(torch.float32))\n",
    "\n",
    "        # Decoder model\n",
    "        tx = F.normalize(text_emb[i], dim=0, eps=1e-8)\n",
    "        tx_proj = F.normalize(proj_head(tx), dim=0, eps=1e-8)\n",
    "        latent_text_dec[i] = tx_proj\n",
    "\n",
    "        sim = (im / im.norm(dim=1)[:, None]) @ tx_proj\n",
    "        amax = np.argmax(sim)\n",
    "        sim_mean_dec[i] = sim[amax]\n",
    "        latent_image_dec[i] = im[amax]\n",
    "\n",
    "        # Contrastive model\n",
    "        tx = F.normalize(text_emb[i], dim=0, eps=1e-8)\n",
    "        tx_proj = F.normalize(proj_head_text(tx), dim=0, eps=1e-8)\n",
    "        im_proj = F.normalize(proj_head_image(im), dim=1, eps=1e-8)\n",
    "        \n",
    "        sim = im_proj @ tx_proj\n",
    "        amax = np.argmax(sim)\n",
    "\n",
    "        latent_text[i] = tx_proj\n",
    "        latent_image[i] = im_proj[amax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12065736",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c961ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "t_to_i, i_to_t = recall_curve(latent_text, latent_image)\n",
    "x = np.arange(1, len(t_to_i)+1) / len(t_to_i)\n",
    "ax.plot(x, t_to_i, label=f\"Text-to-Image (AUC={round(auc(x, t_to_i), 2)})\", color=\"C0\")\n",
    "ax.plot(x, i_to_t, label=f\"Image-to-Text (AUC={round(auc(x, i_to_t), 2)})\", color=\"C1\")\n",
    "\n",
    "ax.set_ylabel(\"Recall@K\")\n",
    "ax.set_xlabel(r\"Normalized K: $\\frac{K}{N}$\")\n",
    "ax.set_title(\"Recall Curve\")\n",
    "ax.plot([0, 1], [0, 1], color='k', ls='--', label=\"Chance\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.savefig(data_dir / \"contrastive_recall.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f0e6c",
   "metadata": {},
   "source": [
    "## Brain-to-Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be46eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from neurovlm.metrics import recall_curve\n",
    "from neurovlm.data import data_dir\n",
    "from neurovlm.retrieval_resources import (\n",
    "    _load_autoencoder, _load_masker, _proj_head_text_mse,\n",
    "    _proj_head_image_infonce, _proj_head_text_infonce,\n",
    ")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from neurovlm.train import which_device\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "from neurovlm.models import Specter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from neurovlm.retrieval_resources import (\n",
    "    _load_masker, _load_autoencoder, _load_networks, _proj_head_text_infonce\n",
    ")\n",
    "from nilearn.plotting import view_img\n",
    "\n",
    "# Load specter\n",
    "device = which_device()\n",
    "specter = Specter(\"allenai/specter2_aug2023refresh\", adapter=\"adhoc_query\", device=device)\n",
    "proj_head_text = _proj_head_text_infonce().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3853b23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load LLM\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"left\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Eval mode and disable gradients\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b85f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(data_dir / \"ngram_labels.npy\")\n",
    "with torch.no_grad():\n",
    "    feature_emb = F.normalize(proj_head_text.to(\"cpu\")(F.normalize(specter(features.tolist()).to(\"cpu\"), dim=1)).cpu(), dim=1)\n",
    "\n",
    "df_neuro, df_pubs, _, _, _, _, text_emb = torch.load(data_dir / \"neurovault.pt\", weights_only=False).values()\n",
    "with torch.no_grad():\n",
    "    text_emb = F.normalize(proj_head_text.to(\"cpu\")(F.normalize(text_emb, dim=1)).cpu(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a182feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = _load_autoencoder().to(device)\n",
    "proj_head_text = _proj_head_text_infonce().to(device)\n",
    "proj_head_image = _proj_head_image_infonce().to(device)\n",
    "\n",
    "nv = torch.load(data_dir / \"neurovault.pt\", weights_only=False)\n",
    "neuro = nv[\"neuro_clustered\"]\n",
    "latent_text = nv[\"text_emb_titles_abstracts\"].to(device)\n",
    "latent_text = F.normalize(latent_text, dim=1)\n",
    "latent_text = F.normalize(proj_head_text(latent_text), dim=1)\n",
    "\n",
    "neuro_emb = torch.zeros((len(df_pubs), 384))\n",
    "imgs_true = torch.zeros((len(df_pubs), 28542))\n",
    "latent_img = torch.zeros((len(df_pubs), 384))\n",
    "\n",
    "for i, doi in enumerate(df_pubs[\"doi\"]):\n",
    "    mask = df_neuro[\"doi\"] == doi\n",
    "    with torch.no_grad():\n",
    "        _neuro_emb = F.normalize(proj_head_image(\n",
    "            autoencoder.encoder(torch.from_numpy(neuro[mask] > 0).float().to(device))\n",
    "        ), dim=1)\n",
    "\n",
    "    imax = (_neuro_emb @ latent_text[i]).argmax()\n",
    "    img = neuro[mask][imax]\n",
    "    imgs_true[i] = torch.from_numpy(img)\n",
    "    latent_img[i] = _neuro_emb[imax]\n",
    "sim = latent_img @ feature_emb.T\n",
    "features = np.array([features[i] for i in sim.argsort(descending=True, dim=1)[:, :20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d8b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a neuroscience editor writing a short wiki-style article from a list of terms. Your job is to provide a predicted title and short summary for each paper.\n",
    "\n",
    "INPUT: a list of neuroscience terms that came from a paper\n",
    "OUTPUT: a prediction of the paper's title and abstract\n",
    "\n",
    "Rules:\n",
    "\n",
    "1) Title (required): 6–12 words. Make it specific and content-based.\n",
    "   - Find commonalities among the term list.\n",
    "   - Use 1–3 of the most informative terms (examples: cognition, network, regions, etc).\n",
    "   - DO NOT use generic titles like: \"Summary\", \"Overview\", \"Brain Network Analysis\", \"A Summary of Terms\".\n",
    "   - Ensure aligns with neuroscience expertise.\n",
    "   - Do not mention disorders or dieases.\n",
    "   - Only include cognition, networks, and regions.\n",
    "\n",
    "2) Summary (3-5 sentence)\n",
    "   - Expand on the title an explain the neuroscience behind it\n",
    "   - Include related but not explicitly mentioned topics.\n",
    "\n",
    "What to include or exclude:\n",
    "1) Exclude disease or disorder (required)\n",
    "   - Do not mention disorders or diease.\n",
    "   - Only include cognition, networks, and regions.\n",
    "2) Be concrete:\n",
    "   - Prefer specific mechanisms, pathways, and canonical associations over vague statements.\n",
    "\n",
    "3) Ignore outlier terms.\n",
    "   - If a term is too vague/ambiguous/unrelated, ignore it in the main text.\n",
    "\n",
    "4) No references. Do not mention this prompt.\n",
    "\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a1b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare messages\n",
    "messages = []\n",
    "for i in range(len(features)):\n",
    "    user_prompt = \", \".join(features[i])\n",
    "    messages.append([\n",
    "        {\"role\": \"system\", \"content\": system_prompt.strip(\"\\n\")},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eccff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")  # safe speed win on Ampere+\n",
    "\n",
    "def batch_generate(messages_batch, max_new_tokens=1000):\n",
    "    # Convert chat messages -> strings once\n",
    "    prompts = [\n",
    "        tokenizer.apply_chat_template(m, tokenize=False, add_generation_prompt=True)\n",
    "        for m in messages_batch\n",
    "    ]\n",
    "    enc = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "        out = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.1,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    # Decode\n",
    "    gen = out[:, enc[\"input_ids\"].shape[1]:]\n",
    "    return tokenizer.batch_decode(gen, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68ab91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c950084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = batch_generate(messages[66:67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0355efc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**Title:** \"Decoding Social Cognition through Interactions between Default Mode and Salience Networks\"\\n\\n**Summary:** The study explores the neural basis of social cognition by examining the interactions between the default mode network (DMN), which is responsible for introspection and self-referential thinking, and the salience network (SN), which detects relevant stimuli and prioritizes attention. The DMN and SN have been implicated in various social cognitive processes, including understanding others\\' mental states (theory of mind). This research investigates how these two networks interact during social tasks, such as evaluating friends versus strangers, and whether they differ when processing familiar versus unfamiliar faces. By analyzing activity patterns in regions like the precuneus, posterior cingulate cortex, and middle cingulate cortex, researchers aim to elucidate the neural mechanisms underlying social cognition and its relationship to individual differences in personality traits, such as empathy and social skills.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b79f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7623e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb96ef3c618444df91f2baea465a226f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Generate\n",
    "batch_size = 16\n",
    "summaries = []\n",
    "for i in tqdm(range(0, len(messages), batch_size)):\n",
    "    summaries.extend(batch_generate(messages[i:i+batch_size], max_new_tokens=1000))\n",
    "\n",
    "# Save\n",
    "with open(data_dir / \"generated_summaries_neurovault.pkl\", \"wb\") as f:\n",
    "    pickle.dump(summaries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e8299c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pubs[\"brain_to_text_summary\"] = summaries\n",
    "df_pubs[\"brain_to_text_summary\"] = df_pubs[\"brain_to_text_summary\"].str.strip()\n",
    "df_pubs[\"brain_to_text_summary\"] = df_pubs[\"brain_to_text_summary\"].str.replace(\"**Title:**\", \"\").str.replace(\"**Summary:**\", \"\").str.replace(\"\\n\\n \", \" [SEP] \").str.replace('\"', \"\").str.strip()\n",
    "df_pubs.to_csv(data_dir / \"neuro_vault_brain_to_text.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bcc956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>brain_to_text_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1111/cdev.12630</td>\n",
       "      <td>Neural Reactivity to Emotional Faces May Media...</td>\n",
       "      <td>Reactivity to others' emotions not only can re...</td>\n",
       "      <td>Neural Mechanisms Underlying Proactive Control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.7554/eLife.15192</td>\n",
       "      <td>Instructed knowledge shapes feedback-driven av...</td>\n",
       "      <td>Socially-conveyed rules and instructions stron...</td>\n",
       "      <td>Decoding Pain Perception through Interactions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.0602659103</td>\n",
       "      <td>Modulation of competing memory systems by dist...</td>\n",
       "      <td>Different forms of learning and memory depend ...</td>\n",
       "      <td>Prefrontal Cortical Regions Modulate Executive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1073/pnas.1518377113</td>\n",
       "      <td>Neural correlates of the LSD experience reveal...</td>\n",
       "      <td>Lysergic acid diethylamide (LSD), the prototyp...</td>\n",
       "      <td>Decoding Episodic Memory Retrieval through Hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1038/s41598-017-09744-7</td>\n",
       "      <td>Intrinsic brain connectivity after partial sle...</td>\n",
       "      <td>Sleep deprivation has been reported to affect ...</td>\n",
       "      <td>Decoding Self-Referential Processing within th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>10.1016/j.neuroimage.2022.119149</td>\n",
       "      <td>Atlas of type 2 dopamine receptors in the huma...</td>\n",
       "      <td>The dopamine system contributes to a multitude...</td>\n",
       "      <td>Decoding Reward Processing in Ventral Striatal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>10.1016/j.appet.2023.106630</td>\n",
       "      <td>The effect of cognitive load on preference and...</td>\n",
       "      <td>Distracted eating can cause overconsumption. W...</td>\n",
       "      <td>Decoding Motor Control Mechanisms in the Premo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>10.1038/s41593-024-01772-7</td>\n",
       "      <td>A potential target for noninvasive neuromodula...</td>\n",
       "      <td>Neuromodulation trials for the treatment of po...</td>\n",
       "      <td>Neural Correlates of Visuospatial Attention du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>10.1212/WNL.0000000000213507</td>\n",
       "      <td>Amyloid and Tau Pathology in Cognitively Unimp...</td>\n",
       "      <td>Female sex and a parental history of Alzheimer...</td>\n",
       "      <td>Decoding Visual Perception through Ventral and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>10.1016/j.neuroimage.2025.121379</td>\n",
       "      <td>Semantic control regions actively generate rul...</td>\n",
       "      <td>Automatic predictions based on past statistica...</td>\n",
       "      <td>Deciphering Language Processing in the Prefron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  doi  \\\n",
       "0                  10.1111/cdev.12630   \n",
       "1                 10.7554/eLife.15192   \n",
       "2             10.1073/pnas.0602659103   \n",
       "3             10.1073/pnas.1518377113   \n",
       "4          10.1038/s41598-017-09744-7   \n",
       "..                                ...   \n",
       "171  10.1016/j.neuroimage.2022.119149   \n",
       "172       10.1016/j.appet.2023.106630   \n",
       "173        10.1038/s41593-024-01772-7   \n",
       "174      10.1212/WNL.0000000000213507   \n",
       "175  10.1016/j.neuroimage.2025.121379   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Neural Reactivity to Emotional Faces May Media...   \n",
       "1    Instructed knowledge shapes feedback-driven av...   \n",
       "2    Modulation of competing memory systems by dist...   \n",
       "3    Neural correlates of the LSD experience reveal...   \n",
       "4    Intrinsic brain connectivity after partial sle...   \n",
       "..                                                 ...   \n",
       "171  Atlas of type 2 dopamine receptors in the huma...   \n",
       "172  The effect of cognitive load on preference and...   \n",
       "173  A potential target for noninvasive neuromodula...   \n",
       "174  Amyloid and Tau Pathology in Cognitively Unimp...   \n",
       "175  Semantic control regions actively generate rul...   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    Reactivity to others' emotions not only can re...   \n",
       "1    Socially-conveyed rules and instructions stron...   \n",
       "2    Different forms of learning and memory depend ...   \n",
       "3    Lysergic acid diethylamide (LSD), the prototyp...   \n",
       "4    Sleep deprivation has been reported to affect ...   \n",
       "..                                                 ...   \n",
       "171  The dopamine system contributes to a multitude...   \n",
       "172  Distracted eating can cause overconsumption. W...   \n",
       "173  Neuromodulation trials for the treatment of po...   \n",
       "174  Female sex and a parental history of Alzheimer...   \n",
       "175  Automatic predictions based on past statistica...   \n",
       "\n",
       "                                 brain_to_text_summary  \n",
       "0    Neural Mechanisms Underlying Proactive Control...  \n",
       "1    Decoding Pain Perception through Interactions ...  \n",
       "2    Prefrontal Cortical Regions Modulate Executive...  \n",
       "3    Decoding Episodic Memory Retrieval through Hip...  \n",
       "4    Decoding Self-Referential Processing within th...  \n",
       "..                                                 ...  \n",
       "171  Decoding Reward Processing in Ventral Striatal...  \n",
       "172  Decoding Motor Control Mechanisms in the Premo...  \n",
       "173  Neural Correlates of Visuospatial Attention du...  \n",
       "174  Decoding Visual Perception through Ventral and...  \n",
       "175  Deciphering Language Processing in the Prefron...  \n",
       "\n",
       "[312 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da5ff85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
