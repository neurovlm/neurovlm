{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from neurovlm.data import get_data_dir\n",
    "from neurovlm.models import Specter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1735a",
   "metadata": {},
   "source": [
    "# Text Encoding\n",
    "\n",
    "This notebook encodes (title, abstract) pairs using Specter. Specter was trained on scientific (title, abstract) pairs, suggesting it is likely to perform well with medium length queries. MiniLM-L6 is expected to better handle short form queries. \n",
    "\n",
    "\n",
    "Use specter is used to to encode (title, abstract) pairs to a 768 dimensional space.\n",
    "\n",
    "> A. Singh, M. D'Arcy, A. Cohan, D. Downey, and S. Feldman, “SciRepEval: A Multi-Format Benchmark for Scientific Document Representations,” in Proc. Conf. Empirical Methods in Natural Language Processing (EMNLP), 2022. [Online]. Available: https://api.semanticscholar.org/CorpusID:254018137\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load publications dataframe\n",
    "data_dir = get_data_dir()\n",
    "df_pubs = pd.read_parquet(data_dir / \"publications_less.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd45418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specter\n",
    "adapter = \"adhoc_query\"\n",
    "specter = Specter(adapter=adapter)\n",
    "\n",
    "# Encode text in batches\n",
    "os.makedirs(\"specter\", exist_ok=True)\n",
    "\n",
    "papers = [title + \"[SEP]\" + abstract\n",
    "          for title, abstract in zip(df_pubs['name'], df_pubs['description'])]\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "for i in tqdm(range(0, len(papers), batch_size), total=len(papers)//batch_size):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        latent = specter(papers[i:i+batch_size])\n",
    "\n",
    "    torch.save(\n",
    "        {\"embeddings\": latent, \"pmid\": df_pubs[\"pmid\"].values[i:i+batch_size]},\n",
    "        f\"specter/encoded_text_specter2_{adapter}_{str(i).zfill(5)}.pt\",\n",
    "        pickle_protocol=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a07f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack vectors and save\n",
    "files = os.listdir(\"specter\")\n",
    "files.sort()\n",
    "\n",
    "latent_text = torch.zeros((len(df_pubs), 768), dtype=torch.float32)\n",
    "pmids_text = np.zeros(len(df_pubs), dtype=int)\n",
    "\n",
    "for idx in range(0, len(df_pubs), batch_size):\n",
    "    latent_text[idx:idx+batch_size] , pmids_text[idx:idx+batch_size] = torch.load(\n",
    "        f\"specter/encoded_text_specter2_{adapter}_{str(idx).zfill(5)}.pt\", weights_only=False\n",
    "    ).values()\n",
    "\n",
    "# Sort the same as df_pubs\n",
    "inds = np.argsort(pmids_text)\n",
    "latent_text = latent_text[inds]\n",
    "\n",
    "# Save\n",
    "latent_text = latent_text / torch.norm(latent_text, dim=1)[:, None]\n",
    "torch.save(latent_text, data_dir / f\"latent_text_specter2_{adapter}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
