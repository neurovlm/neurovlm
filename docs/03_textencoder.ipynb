{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f2e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from neurovlm.data import get_data_dir\n",
    "from neurovlm.models import Specter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1735a",
   "metadata": {},
   "source": [
    "# Text Encoding\n",
    "\n",
    "This notebook encodes (title, abstract) pairs using Specter. Specter was trained on scientific (title, abstract) pairs, suggesting it is likely to perform well with medium length queries. MiniLM-L6 is expected to better handle short form queries. \n",
    "\n",
    "\n",
    "Use specter is used to to encode (title, abstract) pairs to a 768 dimensional space.\n",
    "\n",
    "> A. Singh, M. D'Arcy, A. Cohan, D. Downey, and S. Feldman, “SciRepEval: A Multi-Format Benchmark for Scientific Document Representations,” in Proc. Conf. Empirical Methods in Natural Language Processing (EMNLP), 2022. [Online]. Available: https://api.semanticscholar.org/CorpusID:254018137\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866c125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "# Load publications dataframe\n",
    "data_dir = get_data_dir()\n",
    "df_pubs = pd.read_parquet(data_dir / \"publications_more.parquet\")\n",
    "\n",
    "# Check existing\n",
    "batch_size = 4\n",
    "overwrite = False\n",
    "suffix = \"\"\n",
    "\n",
    "if not overwrite and (data_dir / \"specter\").exists():\n",
    "    # Append to existing results\n",
    "    # Over development, more papers were added and this saved compute\n",
    "    import datetime\n",
    "    import hashlib\n",
    "\n",
    "    latent_text_adhoc_exist, pmids_text_adhoc_exist = torch.load(data_dir / \"latent_specter2_adhoc.pt\", weights_only=False).values()\n",
    "    latent_text_neuro_exist, pmids_text_neuro_exist = torch.load(data_dir / \"latent_specter2_neuro.pt\", weights_only=False).values()\n",
    "    assert (pmids_text_neuro_exist == pmids_text_adhoc_exist).all()\n",
    "\n",
    "    mask = ~df_pubs[\"pmid\"].isin(pmids_text_neuro_exist)\n",
    "    df_pubs = df_pubs[mask]\n",
    "    suffix = \"_\" + hashlib.sha256(\n",
    "        datetime.datetime.now().isoformat().encode(\"utf-8\")\n",
    "    ).hexdigest()[:8] # unique identifier\n",
    "\n",
    "# Load specter\n",
    "specter_neuro = Specter(\"allenai/specter2\", adapter=\"Jerjes/neuro-specter2-multi-pool\")\n",
    "specter_adhoc = Specter(\"allenai/specter2_aug2023refresh\", adapter=\"adhoc_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd45418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f84d44ec24ad0acca2f5c40344450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode text in batches\n",
    "os.makedirs(data_dir / \"specter\", exist_ok=True)\n",
    "\n",
    "papers = [title + \"[SEP]\" + abstract\n",
    "          for title, abstract in zip(df_pubs['name'], df_pubs['description'])]\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "for i in tqdm(range(0, len(papers), batch_size), total=len(papers)//batch_size):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        latent_specter_neuro = specter_neuro(papers[i:i+batch_size])\n",
    "        latent_specter_adhoc = specter_adhoc(papers[i:i+batch_size])\n",
    "\n",
    "    torch.save(\n",
    "        {\"embeddings\": latent_specter_neuro, \"pmid\": df_pubs[\"pmid\"].values[i:i+batch_size]},\n",
    "        data_dir / \"specter\" / f\"encoded_text_specter2_neuro_{str(i).zfill(5)}{suffix}.pt\",\n",
    "        pickle_protocol=5\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        {\"embeddings\": latent_specter_adhoc, \"pmid\": df_pubs[\"pmid\"].values[i:i+batch_size]},\n",
    "        data_dir / \"specter\" / f\"encoded_text_specter2_adhoc_{str(i).zfill(5)}{suffix}.pt\",\n",
    "        pickle_protocol=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66eae71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specter\n",
    "batch_size = 4\n",
    "\n",
    "# Stack batched vectors\n",
    "latent_text_neuro = torch.zeros((len(df_pubs), 768), dtype=torch.float32)\n",
    "latent_text_adhoc = torch.zeros((len(df_pubs), 768), dtype=torch.float32)\n",
    "\n",
    "pmids_text_neuro = np.zeros(len(df_pubs), dtype=int)\n",
    "pmids_text_adhoc = np.zeros(len(df_pubs), dtype=int)\n",
    "\n",
    "for idx in range(0, len(df_pubs), batch_size):\n",
    "\n",
    "    latent_text_neuro[idx:idx+batch_size] , pmids_text_neuro[idx:idx+batch_size] = torch.load(\n",
    "        data_dir / \"specter\" / f\"encoded_text_specter2_neuro_{str(idx).zfill(5)}{suffix}.pt\", weights_only=False\n",
    "    ).values()\n",
    "\n",
    "    latent_text_adhoc[idx:idx+batch_size] , pmids_text_adhoc[idx:idx+batch_size] = torch.load(\n",
    "        data_dir / \"specter\" /  f\"encoded_text_specter2_adhoc_{str(idx).zfill(5)}{suffix}.pt\", weights_only=False\n",
    "    ).values()\n",
    "\n",
    "latent_text_adhoc = latent_text_adhoc / torch.norm(latent_text_adhoc, dim=1)[:, None]\n",
    "latent_text_neuro = latent_text_neuro / torch.norm(latent_text_neuro, dim=1)[:, None]\n",
    "\n",
    "assert np.all(pmids_text_neuro == pmids_text_adhoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c94011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if suffix != \"\":\n",
    "    # Stack with existing\n",
    "    latent_text_adhoc = torch.vstack((latent_text_adhoc_exist, latent_text_adhoc))\n",
    "    latent_text_neuro = torch.vstack((latent_text_neuro_exist, latent_text_neuro))\n",
    "    pmids_text_adhoc = np.concatenate((pmids_text_adhoc_exist, pmids_text_adhoc))\n",
    "    pmids_text_neuro = np.concatenate((pmids_text_neuro_exist, pmids_text_neuro))\n",
    "    assert (pmids_text_adhoc == pmids_text_neuro).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a874c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and save\n",
    "inds = np.argsort(pmids_text_neuro)\n",
    "latent_text_adhoc = latent_text_adhoc[inds]\n",
    "latent_text_neuro = latent_text_neuro[inds]\n",
    "pmids_text_neuro = pmids_text_neuro[inds]\n",
    "pmids_text_adhoc = pmids_text_adhoc[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ac69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"latent\": latent_text_adhoc, \"pmid\": pmids_text_adhoc}, data_dir / \"latent_specter2_adhoc.pt\")\n",
    "torch.save({\"latent\": latent_text_neuro, \"pmid\": pmids_text_neuro}, data_dir / \"latent_specter2_neuro.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
